[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Course schedule",
    "section": "",
    "text": "Course\n      \n      \n        2024\n      \n      \n    \n    \n      Term 1\n      Term 2\n      Term 3\n    \n  \n  \n    HDAT9000\nClinical AI\n\n\n\n\n    HDAT9100\nContext for Health Data Science\n\n\n\n\n    HDAT9200\nStatistical Foundations for Health Data Science\n\n\n\n\n    HDAT9300\nComputing for Health Data Science\n\n\n\n\n    HDAT9400\nData Management & Curation\n\n\n\n\n    HDAT9500\nMachine Learning I\n\n\n\n\n    HDAT9510\nMachine Learning II \n\n\n\n\n    HDAT9600\nStatistical Modelling I \n\n\n\n\n    HDAT9700\nStatistical Modelling II\n\n\n\n\n    HDAT9800\nVisualisation & Communication\n\n\n\n\n    HDAT9900\nDissertation\n\n\n\n\n    HDAT9910\nCapstone\n\n\n\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\nFace-to-Face/Hybrid\n\n\n\n\nOnline\n\n\n\n\n\nMore information can be found by searching for the relevant course online at timetable.unsw.edu.au"
  },
  {
    "objectID": "schedule.html#course-schedule",
    "href": "schedule.html#course-schedule",
    "title": "Course schedule",
    "section": "",
    "text": "Course\n      \n      \n        2024\n      \n      \n    \n    \n      Term 1\n      Term 2\n      Term 3\n    \n  \n  \n    HDAT9000\nClinical AI\n\n\n\n\n    HDAT9100\nContext for Health Data Science\n\n\n\n\n    HDAT9200\nStatistical Foundations for Health Data Science\n\n\n\n\n    HDAT9300\nComputing for Health Data Science\n\n\n\n\n    HDAT9400\nData Management & Curation\n\n\n\n\n    HDAT9500\nMachine Learning I\n\n\n\n\n    HDAT9510\nMachine Learning II \n\n\n\n\n    HDAT9600\nStatistical Modelling I \n\n\n\n\n    HDAT9700\nStatistical Modelling II\n\n\n\n\n    HDAT9800\nVisualisation & Communication\n\n\n\n\n    HDAT9900\nDissertation\n\n\n\n\n    HDAT9910\nCapstone\n\n\n\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\nFace-to-Face/Hybrid\n\n\n\n\nOnline\n\n\n\n\n\nMore information can be found by searching for the relevant course online at timetable.unsw.edu.au"
  },
  {
    "objectID": "schedule.html#key-dates",
    "href": "schedule.html#key-dates",
    "title": "Course schedule",
    "section": "Key dates",
    "text": "Key dates\n\n\n\n\n\n\n\n\n\nMore information on the academic calendar can be found online at student.unsw.edu.au/calendar"
  },
  {
    "objectID": "tutorials/lesson2.html",
    "href": "tutorials/lesson2.html",
    "title": "Step 2. Curating the data",
    "section": "",
    "text": "Overview\nIn order to explore the relationship between birthweight and other factors we are going to need some data. For this guided tutorial we will use data collected at Baystate Medical Center, Springfield, Massachusetts during 1986. This dataset has ten variables collected on 189 mother-baby pairs.\nCareful data curation is essential to a successful health data science project. Relevant tasks include building a data dictionary and developing a data management plan. A data dictionary documents the meaning, source, and format for the variables in a dataset, and the relationship between different datasets. A data management plan defines how data will be stored and accessed throughout the research cycle, from creation and acquisition to usage, and disposal. A well-defined data management plan also addresses risks associated with data, including security and statistical disclosure control rules and algorithms to reduce the possibility of inadvertantly revealing sensitive or private data about inndividuals whose data were used in the analysis.\n\n\nStatistical disclosure control is the statistical science of minimising the risk of accidntally revealing personal or sensitive information about individuals, organisations or communities while maximising the utility of the research results derived from their data. This is important because most health data is private and highly sensitive, and preserving privacy is very important, while at the same time, the results of analyses usually need to be be made public or shared with a wider group.\nYou will learn about statistical disclosure control in the HDAT9400 Data Management & Curation course.\n\n\n\nCreated using Stable Diffusion — human + AI.\n\n\n\n\nDocumenting the available variables\nBefore analysing a dataset its imperative to understand the available data and how it was collected. The list below defines the variables recorded in the birthweight dataset.\n\nlow indicator of birth weight less than 2.5 kg.\nage mother’s age in years.\nlwt mother’s weight in pounds at last menstrual period.\nrace mother’s race (1 = White, 2 = Black, 3 = Other).\nsmoke smoking status during pregnancy.\nptl number of previous premature labours.\nht history of hypertension.\nui presence of uterine irritability.\nftv number of physician visits during the first trimester.\nbwt birth weight in grams.\n\n\n\nViewing the raw data\nIt can often be useful to examine the raw data to get a feel for how it is recorded and any data issues, such as missing data. Below we have printed the first six rows for the birthweight dataset. We can see we have different types of variables available. Some are dichotomous (yes/no responses) like the indicators for smoking and low birthweight. Some are continuous, like maternal age measured in years and birthweight measured in grams.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudying Health Data Science at UNSW Sydney\n\n\n\nAs a health data science student you will learn data wrangling skills and the day to day practicalities of data curation for sound data management in the courses HDAT9400 Context for Health Data Science and HDAT9800 Visualisation and Communication of Health Data.\n\n\n\n\n\n\nData curation\nNotice that the variable race is recorded numerically (1/2/3) rather than as a categorical variable. Looking back at the variable definitions above, we can see that 1 denotes the category White, 2 denotes the category Black and 3 denotes the category Other.\n\n\nNote that these data are from the US. In Australia we usually don’t collect a data item about race specifically, but rather a number of data items relationing to individuals’ country of birth, the languages they speak at home, and whether they identify as Aboriginal and/or Torres Strait Islander peoples (also referred to as First Nations or indigenous peoples).\nWe also use metric units such as kilograms, not old-fashioned imperial units such as pounds (lbs)!\nIf we want to edit a dataset we always do so programatically, i.e. by writing code that will perform the necessary steps. This ensures that any steps we take can always be reproduced. Studying Health Data Science at UNSW you will learn three popular programming languages: SAS, Python and R. There are big advantages to being a programming polyglot—different software packages are particularly good at solving certain kinds of problems. An overview of the software used in different courses is provided here.\nHere we can write some R code to reformat the race variable from numeric to a labelled categorical variable. Note that you can click on the  Code icon to reveal the underlying code.\n\n\nCode\n# Recode race from numeric to a labelled factor variable\nbirthwt$race &lt;- factor(birthwt$race, levels=1:3, labels=c('White', 'Black', 'Other'))\n\n# Print the table\ndatatable(birthwt, rownames=FALSE, options=list(pageLength=6))\n\n\n\n\n\n\n\n\nThat looks better! Now the race variable reflects the underlying coding.\n\n\n\n Test your understanding\nTest your understanding by answering these questions based on the information and interactive table above.\n\nChoose the correct answer Which of these variables is not measured in the dataset?\n\n Number of Physician visits during the first trimester Number of previous premature labours Presence of gestational diabetes Smoking status during pregnancy\n\nFill in the blank There is an outlier in the maternal age variable. The oldest mum was  years old at the time of birth.\n\n\n\n\nNext steps\n\n\n Back to the main menu \n\n\n Step 3. Exploring the data"
  },
  {
    "objectID": "tutorials/lesson6.html",
    "href": "tutorials/lesson6.html",
    "title": "Step 6. Conclusions",
    "section": "",
    "text": "You’ve almost reached the end of the guided tutorial—congratulations!\nThe final step is to review our findings and draw our conclusions. Let’s recap our original research questions:\n\nWhat is the relationship between smoking during pregnancy and a child’s birthweight?\nCan maternal factors measured during pregnancy be used to accurately predict infants at risk of low birthweight?\n\nIn relation to Question 1, unsurprisingly we found that there was a significant negative association between maternal smoking and birthweight. Children of mothers who smoked during pregnancy were born around 284 grams lighter on average, compared to children of non-smokers. This kind of evidence has been long-used to promote anti-smoking public health campaigns and target supports to expectant mothers.\nIn relation to Question 2, we built a decision tree model that could predict children at risk of low birth weight at birth with 71.5% accuracy, based on information available by the end of the first trimester.\n\n\n\nCreated using Stable Diffusion — human + AI.\n\n\n\nConclusions\nWe can conclude that (i) maternal smoking is negatively associated with birthweight and (ii) it is possible to predict low birthweight based on characteristics observed during the first trimester.\nInterestingly, even though children born to maternal smokers were lighter at birth, maternal smoking was not a good predictor of low birthweight in the decision tree model. One possible reason for this is that, given the other health variables, knowledge of smoking status didn’t add much extra.\n\n\nLimitations\nIn this introductory tutorial, we’ve crafted simple, yet practical research questions to showcase the incredible utility of applying data science to health-related inquiries. From exploring associations between smoking and birth outcomes to developing predictive models, these beginner-friendly examples serve as stepping stones into the vast possibilities of health data analysis.\nWhile the simplicity of these questions allows for an easy entry point, it’s important to note that real-world health data analyses can be much more complex. Rather than look at the association between smoking and birthweight we could delve into the underlying causal processes as well as consider the safety of smoking cessation therapies on birth outcomes. When thinking about prediction, there are many other methods we could explore to optimise the model accuracy.\nAs you delve deeper into this field, you’ll discover the richness of intricate datasets and the nuanced challenges of addressing complex health-related queries. Get ready to unlock the potential of health data science, where even the simplest questions pave the way for uncovering profound insights in the diverse and dynamic landscape of healthcare research!\n\n\n\n\n\n\n\n\nStudying Health Data Science at UNSW Sydney\n\n\n\nInterested in a career in Health Data Science?\nClick here to find out about our short courses and postgraduate programs including further information on how to apply.\nCheck out the student blog to read about our students’ experiences studying health data science.\n\n\n\n\n\n\nNext Steps\nIn a real analysis, the next phase would focus on disseminating your research findings though conference presentations, reports and academic publications. Collaborating with healthcare professionals, policymakers, and community stakeholders provides avenues for translating your research into actionable outcomes, fostering positive change in real-world health practices.\nYou can read about the research undertaken by the Health Data Science course conveners in our meet the teaching team section on our student hub. Examples of recent academic articles published by faculty and postgraduate students from the Centre for Big Data Research in Health can be viewed online here.\nFor now, the only question you have to answer is, is health data science for you? Apply here"
  },
  {
    "objectID": "tutorials/lesson5.html",
    "href": "tutorials/lesson5.html",
    "title": "Step 5. Predictive modelling",
    "section": "",
    "text": "Overview\nNow let’s turn to our second research question, Can maternal factors measured during pregnancy be used to accurately predict infants at risk of low birthweight?\nThis is a question about prediction—we want to forecast a future outcome based on information available at some specific point in time. Some of the methods that can be used to answer these questions are regression methods, decision trees, random forests, gradient boosted trees, or neural networks.\nIn this scenario, we want to predict children at high risk of being born with low birthweight based on maternal characteristics observable during pregnancy. The potential predictive variables in our dataset are available from the end of the first trimester so this is our “Time Zero”, the point in time a prediction could be made. Predictions of low birthweight could be useful to inform care decisions during the second and third trimesters, such as more regular monitoring or provision of nutritional supplements.\n\n\n\nCreated using Stable Diffusion — human + AI.\n\n\n\n\nDecision Trees\nTo predict low birthweight we will use a model called a single decision tree. This is a type of algorithm that processes data by asking a series of “yes” or “no” questions about different variables—conventionally referred to as features—measured in the dataset. The resulting path of decisions resembles a tree with many branches, hence the name “decision tree”.\nThe first question is at the top of the tree, known as the “root” (the “root” is often shown on the left to allow left-to-right reading of the tree). Based on the answer to the first question, you follow one of the branches to the next question. Each branch represents a decision or a choice. At each step (or “node”), there’s a new question. Your answers guide you through the tree, moving from one question to the next. Eventually, you reach the end of a branch, which is like the “leaves” of the tree. The leaves give you the final prediction for a given individual, based on their characteristics. In this case, it will be a prediction of whether or not a baby will be born with low birthweight.\n\n\n\n\n\n\nA more accurate representation of our decision tree! (image generated using Midjourney AI)\n\n\n\nWe will split the dataset in two to create a “training” set and a “test” set. We train our model using the training set. This means the training data is what the model uses to learn how to predict whether a baby will be born with low weight, based on the available features.\nThe test set acts as a simulation of unseen data, representing information that the algorithm hasn’t encountered or learned from during training. Using a training set to train the model and a test set to test the model is essential so that the model’s generalisation performance can be thoroughly assessed, ensuring its ability to make accurate predictions on new, unseen data and confirming its reliability beyond the training dataset.\nThis analysis is implemented using Python, perhaps the most popular programming language for machine learning. Click the  Code icon below to view the underlying python code to prepare the dataset and run the decision tree analysis.\n\n\nCode\n# Recode categorical variables\nbirth_weight_dataset[['patient_id','low','race','smoke','ht','ui']] = birth_weight_dataset[['patient_id','low','race','smoke','ht','ui']].astype('category')\n\n# Drop unnecessary variables\nbirth_weight_dataset= birth_weight_dataset.drop(['patient_id', 'bwt'], axis=1)\n\n# Define the predictor variables\nX = birth_weight_dataset.drop(axis=1, columns=['low'])\n\n# Define the outcome variable\ny = birth_weight_dataset[['low']].values\n\n# Define the test set and the training set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0, shuffle=1, test_size = 0.20)\n\n# Import the decision tree classifier from the sci-kit learn library\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Run the decision tree algorithm\nml_model_01 = DecisionTreeClassifier(random_state=0)\nml_model_01.fit(X_train, y_train)\n\n\nDecisionTreeClassifier(random_state=0)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeClassifierDecisionTreeClassifier(random_state=0)\n\n\n\n\nAssess the model accuracy\nBelow we have printed the model accuracy for the training set and the test set. The model accuracy tells us how well the decision tree is doing at classifying children as low birthweight or not based on their mother’s characteristics. The accuracy statistic can take values between 0 and 1, with 1 representing 100% accuracy—perfect predictions. An accuracy of 0.5 would suggest that the model is performing no better than random chance.\n\n\nBalanced accuracy on training set: 1.000\n\n\nBalanced accuracy on test set: 0.612\n\n\nThe accuracy in the training set is 1.000 and the accuracy in the training set is 0.612. This means that the model is performing perfectly on the training data but isn’t doing great when it encounters the unseen data in the test set.\nThis problem is known as overfitting. The model has learned how to predict low or normal birthweight based on the input features but only in the training set. When the model is given an unknown set, the test set, the model performance is much worse. This means the model is not able to generalise to new unseen data and hence, we say the model is overfitted.\nLet’s plot our tree and see how this has happened.\n\n\n\n\n\n\n\n\nTree\n\n  \n\n0\n\n ptl &lt;= 0.5 samples = 151 value = [104, 47] class = No   \n\n1\n\n lwt &lt;= 106.0 samples = 132 value = [97, 35] class = No   \n\n0-&gt;1\n\n  True   \n\n78\n\n age &lt;= 31.5 samples = 19 value = [7, 12] class = Yes   \n\n0-&gt;78\n\n  False   \n\n2\n\n age &lt;= 22.5 samples = 22 value = [11, 11] class = No   \n\n1-&gt;2\n\n    \n\n13\n\n ui &lt;= 0.5 samples = 110 value = [86, 24] class = No   \n\n1-&gt;13\n\n    \n\n3\n\n ftv &lt;= 1.5 samples = 14 value = [10, 4] class = No   \n\n2-&gt;3\n\n    \n\n8\n\n age &lt;= 29.0 samples = 8 value = [1, 7] class = Yes   \n\n2-&gt;8\n\n    \n\n4\n\n lwt &lt;= 82.5 samples = 11 value = [10, 1] class = No   \n\n3-&gt;4\n\n    \n\n7\n\n samples = 3 value = [0, 3] class = Yes   \n\n3-&gt;7\n\n    \n\n5\n\n samples = 1 value = [0, 1] class = Yes   \n\n4-&gt;5\n\n    \n\n6\n\n samples = 10 value = [10, 0] class = No   \n\n4-&gt;6\n\n    \n\n9\n\n samples = 6 value = [0, 6] class = Yes   \n\n8-&gt;9\n\n    \n\n10\n\n lwt &lt;= 100.0 samples = 2 value = [1, 1] class = No   \n\n8-&gt;10\n\n    \n\n11\n\n samples = 1 value = [1, 0] class = No   \n\n10-&gt;11\n\n    \n\n12\n\n samples = 1 value = [0, 1] class = Yes   \n\n10-&gt;12\n\n    \n\n14\n\n ht &lt;= 0.5 samples = 97 value = [79, 18] class = No   \n\n13-&gt;14\n\n    \n\n69\n\n lwt &lt;= 122.5 samples = 13 value = [7, 6] class = No   \n\n13-&gt;69\n\n    \n\n15\n\n age &lt;= 27.5 samples = 89 value = [75, 14] class = No   \n\n14-&gt;15\n\n    \n\n62\n\n lwt &lt;= 211.0 samples = 8 value = [4, 4] class = No   \n\n14-&gt;62\n\n    \n\n16\n\n lwt &lt;= 109.5 samples = 67 value = [53, 14] class = No   \n\n15-&gt;16\n\n    \n\n61\n\n samples = 22 value = [22, 0] class = No   \n\n15-&gt;61\n\n    \n\n17\n\n samples = 1 value = [0, 1] class = Yes   \n\n16-&gt;17\n\n    \n\n18\n\n age &lt;= 26.5 samples = 66 value = [53, 13] class = No   \n\n16-&gt;18\n\n    \n\n19\n\n ftv &lt;= 2.5 samples = 65 value = [53, 12] class = No   \n\n18-&gt;19\n\n    \n\n60\n\n samples = 1 value = [0, 1] class = Yes   \n\n18-&gt;60\n\n    \n\n20\n\n lwt &lt;= 186.0 samples = 61 value = [51, 10] class = No   \n\n19-&gt;20\n\n    \n\n55\n\n lwt &lt;= 119.0 samples = 4 value = [2, 2] class = No   \n\n19-&gt;55\n\n    \n\n21\n\n age &lt;= 15.5 samples = 56 value = [48, 8] class = No   \n\n20-&gt;21\n\n    \n\n52\n\n smoke &lt;= 0.5 samples = 5 value = [3, 2] class = No   \n\n20-&gt;52\n\n    \n\n22\n\n age &lt;= 14.5 samples = 2 value = [1, 1] class = No   \n\n21-&gt;22\n\n    \n\n25\n\n lwt &lt;= 136.5 samples = 54 value = [47, 7] class = No   \n\n21-&gt;25\n\n    \n\n23\n\n samples = 1 value = [1, 0] class = No   \n\n22-&gt;23\n\n    \n\n24\n\n samples = 1 value = [0, 1] class = Yes   \n\n22-&gt;24\n\n    \n\n26\n\n race &lt;= 1.5 samples = 40 value = [36, 4] class = No   \n\n25-&gt;26\n\n    \n\n43\n\n age &lt;= 18.5 samples = 14 value = [11, 3] class = No   \n\n25-&gt;43\n\n    \n\n27\n\n samples = 15 value = [15, 0] class = No   \n\n26-&gt;27\n\n    \n\n28\n\n age &lt;= 24.5 samples = 25 value = [21, 4] class = No   \n\n26-&gt;28\n\n    \n\n29\n\n lwt &lt;= 119.5 samples = 23 value = [20, 3] class = No   \n\n28-&gt;29\n\n    \n\n40\n\n race &lt;= 2.5 samples = 2 value = [1, 1] class = No   \n\n28-&gt;40\n\n    \n\n30\n\n samples = 11 value = [11, 0] class = No   \n\n29-&gt;30\n\n    \n\n31\n\n age &lt;= 17.5 samples = 12 value = [9, 3] class = No   \n\n29-&gt;31\n\n    \n\n32\n\n smoke &lt;= 0.5 samples = 3 value = [1, 2] class = Yes   \n\n31-&gt;32\n\n    \n\n35\n\n lwt &lt;= 120.5 samples = 9 value = [8, 1] class = No   \n\n31-&gt;35\n\n    \n\n33\n\n samples = 2 value = [0, 2] class = Yes   \n\n32-&gt;33\n\n    \n\n34\n\n samples = 1 value = [1, 0] class = No   \n\n32-&gt;34\n\n    \n\n36\n\n age &lt;= 21.5 samples = 3 value = [2, 1] class = No   \n\n35-&gt;36\n\n    \n\n39\n\n samples = 6 value = [6, 0] class = No   \n\n35-&gt;39\n\n    \n\n37\n\n samples = 2 value = [2, 0] class = No   \n\n36-&gt;37\n\n    \n\n38\n\n samples = 1 value = [0, 1] class = Yes   \n\n36-&gt;38\n\n    \n\n41\n\n samples = 1 value = [1, 0] class = No   \n\n40-&gt;41\n\n    \n\n42\n\n samples = 1 value = [0, 1] class = Yes   \n\n40-&gt;42\n\n    \n\n44\n\n samples = 1 value = [0, 1] class = Yes   \n\n43-&gt;44\n\n    \n\n45\n\n lwt &lt;= 139.0 samples = 13 value = [11, 2] class = No   \n\n43-&gt;45\n\n    \n\n46\n\n samples = 1 value = [0, 1] class = Yes   \n\n45-&gt;46\n\n    \n\n47\n\n ftv &lt;= 1.5 samples = 12 value = [11, 1] class = No   \n\n45-&gt;47\n\n    \n\n48\n\n samples = 10 value = [10, 0] class = No   \n\n47-&gt;48\n\n    \n\n49\n\n race &lt;= 1.5 samples = 2 value = [1, 1] class = No   \n\n47-&gt;49\n\n    \n\n50\n\n samples = 1 value = [0, 1] class = Yes   \n\n49-&gt;50\n\n    \n\n51\n\n samples = 1 value = [1, 0] class = No   \n\n49-&gt;51\n\n    \n\n53\n\n samples = 3 value = [3, 0] class = No   \n\n52-&gt;53\n\n    \n\n54\n\n samples = 2 value = [0, 2] class = Yes   \n\n52-&gt;54\n\n    \n\n56\n\n samples = 1 value = [1, 0] class = No   \n\n55-&gt;56\n\n    \n\n57\n\n smoke &lt;= 0.5 samples = 3 value = [1, 2] class = Yes   \n\n55-&gt;57\n\n    \n\n58\n\n samples = 1 value = [1, 0] class = No   \n\n57-&gt;58\n\n    \n\n59\n\n samples = 2 value = [0, 2] class = Yes   \n\n57-&gt;59\n\n    \n\n63\n\n age &lt;= 20.0 samples = 6 value = [2, 4] class = Yes   \n\n62-&gt;63\n\n    \n\n68\n\n samples = 2 value = [2, 0] class = No   \n\n62-&gt;68\n\n    \n\n64\n\n samples = 1 value = [1, 0] class = No   \n\n63-&gt;64\n\n    \n\n65\n\n lwt &lt;= 125.0 samples = 5 value = [1, 4] class = Yes   \n\n63-&gt;65\n\n    \n\n66\n\n samples = 1 value = [1, 0] class = No   \n\n65-&gt;66\n\n    \n\n67\n\n samples = 4 value = [0, 4] class = Yes   \n\n65-&gt;67\n\n    \n\n70\n\n age &lt;= 19.5 samples = 8 value = [6, 2] class = No   \n\n69-&gt;70\n\n    \n\n75\n\n age &lt;= 19.5 samples = 5 value = [1, 4] class = Yes   \n\n69-&gt;75\n\n    \n\n71\n\n lwt &lt;= 109.5 samples = 3 value = [1, 2] class = Yes   \n\n70-&gt;71\n\n    \n\n74\n\n samples = 5 value = [5, 0] class = No   \n\n70-&gt;74\n\n    \n\n72\n\n samples = 1 value = [1, 0] class = No   \n\n71-&gt;72\n\n    \n\n73\n\n samples = 2 value = [0, 2] class = Yes   \n\n71-&gt;73\n\n    \n\n76\n\n samples = 1 value = [1, 0] class = No   \n\n75-&gt;76\n\n    \n\n77\n\n samples = 4 value = [0, 4] class = Yes   \n\n75-&gt;77\n\n    \n\n79\n\n ptl &lt;= 2.5 samples = 17 value = [5, 12] class = Yes   \n\n78-&gt;79\n\n    \n\n90\n\n samples = 2 value = [2, 0] class = No   \n\n78-&gt;90\n\n    \n\n80\n\n ftv &lt;= 0.5 samples = 16 value = [4, 12] class = Yes   \n\n79-&gt;80\n\n    \n\n89\n\n samples = 1 value = [1, 0] class = No   \n\n79-&gt;89\n\n    \n\n81\n\n samples = 7 value = [0, 7] class = Yes   \n\n80-&gt;81\n\n    \n\n82\n\n ui &lt;= 0.5 samples = 9 value = [4, 5] class = Yes   \n\n80-&gt;82\n\n    \n\n83\n\n lwt &lt;= 95.0 samples = 7 value = [2, 5] class = Yes   \n\n82-&gt;83\n\n    \n\n88\n\n samples = 2 value = [2, 0] class = No   \n\n82-&gt;88\n\n    \n\n84\n\n samples = 1 value = [1, 0] class = No   \n\n83-&gt;84\n\n    \n\n85\n\n lwt &lt;= 156.0 samples = 6 value = [1, 5] class = Yes   \n\n83-&gt;85\n\n    \n\n86\n\n samples = 5 value = [0, 5] class = Yes   \n\n85-&gt;86\n\n    \n\n87\n\n samples = 1 value = [1, 0] class = No   \n\n85-&gt;87\n\n   \n\n\n\n\n\n\n\nHere you can see the mechanics of the decision tree. The first question relates to the variable ptl i.e. number of previous premature labours.\n\nIf the answer is no previous premature labours (i.e. \\(\\le 0.5\\)) the next question asks whether or not lwt (weight at last menstrual period) was \\(\\le 106\\) lbs.\nIf the answer is one or more previous premature labours (i.e. \\(\\gt 0.5\\)) the the next question asks whether or not maternal age was \\(\\le 31.5\\) years.\n\nAs you can see, if you allow the tree to grow without any limitation, the tree continues asking “yes/no” questions, branching out more and more. This unrestricted growth can result in a highly complex model that captures not only the underlying patterns but also the noise in the training data. As is the case here, such a tree may perform exceptionally well on the training dataset but fail to predict accurately on new, unseen data due to its over-specialisation (overfitting).\n\n\n\n\n\n\n\n\nStudying Health Data Science at UNSW Sydney\n\n\n\nEmbark on a captivating journey into the realm of machine learning with our course HDAT9500 Machine Learning I, where you’ll gain a comprehensive introduction to core techniques applied in the realm of health applications. From mastering algorithms such as linear regression and classification to exploring the intricacies of tree-based methods, clustering, dimensionality reduction, and neural networks, this course equips you with the essential tools to revolutionize healthcare through the power of machine learning.\nExplore the dynamic world of machine learning and artificial intelligence in our exciting elective course, HDAT9510 Machine Learning II. Delve into cutting-edge applications and witness firsthand the rapid evolution of these transformative technologies, preparing yourself for the forefront of innovation in today’s ever-changing landscape.\n\n\n\n\n\n\nPre-pruning a tree\nIn order to avoid this overfitting, let’s impose some restrictions in our decision tree. We are going to be “gardeners” and apply pre-pruning to our tree—this will stop the tree from growing into a perfect fit to the training data.\nLet’s restrict the depth of our tree, to let’s say, four branches. This is done by specifying the max_depth = 4 option in the code below.\n\n\nCode\nml_model_02 = DecisionTreeClassifier(random_state=0, max_depth = 4)\nml_model_02.fit(X_train, y_train)\n\n\nDecisionTreeClassifier(max_depth=4, random_state=0)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeClassifierDecisionTreeClassifier(max_depth=4, random_state=0)\n\n\nBelow is our pre-pruned tree. You will notice it is much simpler: the algorithm is using fewer “yes/no” questions to make a final decision, with a maximum of four branches.\n\n\n\n\n\n\n\n\nTree\n\n  \n\n0\n\n ptl &lt;= 0.5 samples = 151 value = [104, 47] class = No   \n\n1\n\n lwt &lt;= 106.0 samples = 132 value = [97, 35] class = No   \n\n0-&gt;1\n\n  True   \n\n16\n\n age &lt;= 31.5 samples = 19 value = [7, 12] class = Yes   \n\n0-&gt;16\n\n  False   \n\n2\n\n age &lt;= 22.5 samples = 22 value = [11, 11] class = No   \n\n1-&gt;2\n\n    \n\n9\n\n ui &lt;= 0.5 samples = 110 value = [86, 24] class = No   \n\n1-&gt;9\n\n    \n\n3\n\n ftv &lt;= 1.5 samples = 14 value = [10, 4] class = No   \n\n2-&gt;3\n\n    \n\n6\n\n age &lt;= 29.0 samples = 8 value = [1, 7] class = Yes   \n\n2-&gt;6\n\n    \n\n4\n\n samples = 11 value = [10, 1] class = No   \n\n3-&gt;4\n\n    \n\n5\n\n samples = 3 value = [0, 3] class = Yes   \n\n3-&gt;5\n\n    \n\n7\n\n samples = 6 value = [0, 6] class = Yes   \n\n6-&gt;7\n\n    \n\n8\n\n samples = 2 value = [1, 1] class = No   \n\n6-&gt;8\n\n    \n\n10\n\n ht &lt;= 0.5 samples = 97 value = [79, 18] class = No   \n\n9-&gt;10\n\n    \n\n13\n\n lwt &lt;= 122.5 samples = 13 value = [7, 6] class = No   \n\n9-&gt;13\n\n    \n\n11\n\n samples = 89 value = [75, 14] class = No   \n\n10-&gt;11\n\n    \n\n12\n\n samples = 8 value = [4, 4] class = No   \n\n10-&gt;12\n\n    \n\n14\n\n samples = 8 value = [6, 2] class = No   \n\n13-&gt;14\n\n    \n\n15\n\n samples = 5 value = [1, 4] class = Yes   \n\n13-&gt;15\n\n    \n\n17\n\n ptl &lt;= 2.5 samples = 17 value = [5, 12] class = Yes   \n\n16-&gt;17\n\n    \n\n22\n\n samples = 2 value = [2, 0] class = No   \n\n16-&gt;22\n\n    \n\n18\n\n ftv &lt;= 0.5 samples = 16 value = [4, 12] class = Yes   \n\n17-&gt;18\n\n    \n\n21\n\n samples = 1 value = [1, 0] class = No   \n\n17-&gt;21\n\n    \n\n19\n\n samples = 7 value = [0, 7] class = Yes   \n\n18-&gt;19\n\n    \n\n20\n\n samples = 9 value = [4, 5] class = Yes   \n\n18-&gt;20\n\n   \n\n\n\n\n\n\n\nBelow we have printed off the accuracy report for the training set and the test set for the pre-pruned decision tree. Remember, values closer to 1 indicate better predictive ability.\n\n\nBalanced accuracy on training set: 0.742\n\n\nBalanced accuracy on test set: 0.715\n\n\nThe accuracy in the training set is now 0.742. This is actually worse than the original unpruned tree, which had an accuracy of 1.0 in the training dataset. But, importantly, the accuracy in the test dataset is now 0.715. This has risen from the previous value of 0.612 based on the unpruned tree. By prepruning the tree, we have stopped the model from focusing too much on the training data–the problem of overfitting. As a result, the decision tree does better when tested on unseen data.\n\n\nUnderstanding the predictions\nTo get a better understanding of the predictive performance of decision tree model we can compare the true values for low birthweight to the predicted values. This kind of comparison is called a Confusion Matrix. Below is the confusion matrix for the predictions in the training dataset.\n\n\nCode\n# Visualising the Classification Report and the Confusion Matrix for the training set:\nfrom sklearn.metrics import classification_report\n\n# Temporary variable for plotting purposes\nax_cm= plt.subplot()\n\nimport seaborn as sns\nsns.heatmap(confusion_matrix_model_02_train, annot=True, fmt='.0f', ax= ax_cm, cmap=['#399de5', '#e58139', 'red', 'green'], cbar=False, center=50, vmin=0, vmax=100)\n\n# labels, title and ticks\nax_cm.set_xlabel('Predicted value for low birthweight')\nax_cm.set_ylabel('Birthweight')\nax_cm.set_title('Confusion Matrix for the training dataset')\nax_cm.xaxis.set_ticklabels(['Normal', 'Low'])\nax_cm.yaxis.set_ticklabels(['Normal', 'Low'])\n\n\n\n\n\n\nIn the training dataset, there were 104 babies born with normal birthweight. Of these, 99 were correctly predicted to have normal birthweight and 5 were incorrectly predicted to have low birthweight.\nThere were 47 children born with low birthweight. Of these, 22 were incorrectly predicted to have normal birthweight and 25 were correctly predicted to have low birthweight.\n\nBelow is the equivalent confusion matrix based on the model for the test dataset.\n\n\n\n\n\n\n\nFeature importance\nInvestigating and presenting a feature importance graph after training a decision tree model is useful for gaining insights into the model’s decision-making process and understanding which features have the most significant impact on the predictions. The graph below presents the feature importance for the pre-pruned decision tree. Here, the importance of individual features is calculated based on the number of times a feature is used to make a decision at a node.\n\n\nCode\nimport numpy as np\n\ndef plot_feature_importances(model):\n    plt.rcParams[\"figure.figsize\"] = (8,5)\n    # Sort feature importances in ascending order\n    indices = np.argsort(model.feature_importances_)\n\n    # Rearrange feature names so they match the sorted feature importances\n    columns_name = [X.columns[i] for i in indices]\n    # columns_name = [\"Race\", \"Smoking\", \"Hypertension\", \"UI\", \"Weight\", \"Physician visits during first trimester\", \"Previous premature labours\", \"Maternal age\"]\n\n    # Create plot\n    plt.figure()\n    plt.title(\"Feature Importance\")\n    plt.xlabel(\"Feature\")\n    plt.ylabel(\"Feature Importance\")\n    plt.barh(range(X.shape[1]), model.feature_importances_[indices], color='#399de5')\n    plt.yticks(range(X.shape[1]), columns_name)\n    plt.show()\n    \nplot_feature_importances(ml_model_02)    \n\n\n\n\n\nThe variable age (maternal age) is shown to be most important, which makes sense as this is used in three decision nodes. The next important features are ptl (number of previous premature labours) and ftv (number of physician visits during the first trimester), which are used at two nodes each.\nInterestingly, the variables smoke (smoking status during pregnancy) and race (mother’s race) are not used at any nodes making them least important in predicting low birthweight in this model.\n\n\n\n Test your understanding\nTest your understanding by answering these questions based on the analysis above.\n\nTrue or False The original unpruned tree will be better able to generalise to unseen data TRUEFALSE\nFill in the blank Based on the confusion matrix for the test dataset, there were  babies with low birthweight. Of these,  were correctly predicted as having low birth weight and  were incorrectly predicted as having normal birthweight.\nChoose the correct answer According to the pre-pruned decision tree, the most important feature was low (indicator of birth weight less than 2.5 kg)age (mother’s age in years)lwt (mother’s weight in pounds at last menstrual period)race (mother’s race)smoke (smoking status during pregnancy)ptl (number of previous premature labours)ht (history of hypertension)ui (presence of uterine irritability)ftv (number of physician visits during the first trimester)bwt (birth weight in grams)\n\n\n\n\nNext steps\n\n\n Back to the main menu \n\n\n Step 6. Conclusion"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Health Data Science Student Blog",
    "section": "",
    "text": "Advent of Code\n\n\n\n\n\n\n\nHealth Data Science\n\n\nAdvent of Code\n\n\n\n\nSean discusses the popular and festive-themed annual coding challenge Advent of Code\n\n\n\n\n\n\nNov 30, 2023\n\n\nSean de Boo\n\n\n\n\n\n\n  \n\n\n\n\nWhat If: Using Data Storytelling to Illustrate Health Inequality in England\n\n\n\n\n\n\n\nHealth Data Science\n\n\nData Visualisation\n\n\nScrollytelling\n\n\nHealth Inequality\n\n\n\n\nOwen discusses how he combined story-telling and interactive data visualisation to reveal the cascading effects of socio-economic factors on health outcomes\n\n\n\n\n\n\nOct 10, 2023\n\n\nOwen Cho\n\n\n\n\n\n\n  \n\n\n\n\nApplying literate programming techniques in the workplace\n\n\n\n\n\n\n\nHealth Data Science\n\n\nLiterate Programming\n\n\n\n\nCalum discusses the power of literate programming to communicate with clincal collaborators\n\n\n\n\n\n\nSep 11, 2023\n\n\nCalum Nicholson\n\n\n\n\n\n\n  \n\n\n\n\nMedical students living the Clinical AI dream\n\n\n\n\n\n\n\nHealth Data Science\n\n\nClinical AI\n\n\n\n\nLiam and Elisabeth discuss their experience studying on the Clinical AI stream\n\n\n\n\n\n\nJun 29, 2023\n\n\nLiam Dettmann Hughes and Elisabeth Abhayaratna\n\n\n\n\n\n\n  \n\n\n\n\nCBDRH Datathon: a taste of a (real) synthetic dataset\n\n\n\n\n\n\n\nHealth Data Science\n\n\ndatathon\n\n\nsynthetic data\n\n\nHIV\n\n\n\n\nIvy discusses her experience at the first CBDRH Health Data Science datathon\n\n\n\n\n\n\nJun 6, 2023\n\n\nIvy Cerelia Valerie\n\n\n\n\n\n\n  \n\n\n\n\nBridging the chasm of expectations and reality with real-world projects\n\n\n\n\n\n\n\nHealth Data Science\n\n\nelectronic medical records\n\n\npublishing research\n\n\n\n\nDanielle discusses her work at the interface of data science and clinical practice.\n\n\n\n\n\n\nApr 12, 2023\n\n\nDanielle Ritz Shala\n\n\n\n\n\n\n  \n\n\n\n\nStudying Health Data Science as a junior doctor\n\n\n\n\n\n\n\nHealth Data Science\n\n\nwork-life balance\n\n\npublishing research\n\n\n\n\nLucinda discusses her experience completing the HDS Masters Program while working as a junior doctor\n\n\n\n\n\n\nApr 4, 2023\n\n\nLucinda Roper\n\n\n\n\n\n\n  \n\n\n\n\nBalancing life and study\n\n\n\n\n\n\n\nHealth Data Science\n\n\nwork-life balance\n\n\n\n\nJason discusses successfully navigating the Health Data Science Masters while balancing work, family and other life committments\n\n\n\n\n\n\nFeb 6, 2023\n\n\nJason Meyer\n\n\n\n\n\n\n  \n\n\n\n\nWinning the SAS Cortex Analytics Simulation Challenge\n\n\n\n\n\n\n\nHealth Data Science\n\n\nSAS\n\n\nCortex\n\n\n\n\nManny discusses winning the SAS Cortex Analytics Simulation 5 Day Challenge\n\n\n\n\n\n\nJan 13, 2023\n\n\nManny Adachi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "people/mark.html",
    "href": "people/mark.html",
    "title": "Mark Hanly",
    "section": "",
    "text": "Mark is a Senior Lecturer and convenor on the course HDAT9700 statistical modelling II.  m.hanly@unsw.edu.au"
  },
  {
    "objectID": "people/mark.html#what-publication-are-you-most-proud-of",
    "href": "people/mark.html#what-publication-are-you-most-proud-of",
    "title": "Mark Hanly",
    "section": "What publication are you most proud of?",
    "text": "What publication are you most proud of?\nThe paper that comes to mind is Modelling vaccination capacity at mass vaccination hubs and general practice clinics: a simulation study1 We started this paper in early 2021, when it became clear that vaccination hubs were going to be an important part of the COVID-19 mass vaccination program. At the time, there was limited information available on the logistics of delivering vaccinations at scale so in this study we used a special class of model—queue network models—to try to figure out the sweet spot between number of vaccinations per day, staffing levels and target processing times.\nI love this paper because it was addressing a very real and practical question. To inform the analysis I spent time at the Royal Prince Alfred Hospital COVID Vaccination Clinic speaking to the health staff preparing and delivering vaccinations to better understand the process we were modelling. I also presented the completed work to the NSW Health Sydney Local Health District, as they prepared to set up their mass vaccination hub at Olympic Park.\nThe other nice aspect of this paper was the many ways we made the work accessible. To accompany the analysis we developed a shiny app that allows users to rerun our models, or to run alternative queuing models based on their own circumstances (number of staff, target daily vaccinations etc). As a companion to the academic paper, we also published an article in The Conversation to help share the lessons from our work as broadly as possible. Finally, all of the code from the analysis was made available on GitHub, following best practice for open science and reproducibility."
  },
  {
    "objectID": "people/mark.html#whats-the-most-important-take-home-message-from-your-course",
    "href": "people/mark.html#whats-the-most-important-take-home-message-from-your-course",
    "title": "Mark Hanly",
    "section": "What’s the most important take home message from your course?",
    "text": "What’s the most important take home message from your course?\nIn Stats Modelling II we cover a range of modelling techniques but the modelling approach always depends on the question and the data. So I’d say the most important lesson is that before doing any analysis you need to be able to fully articulate your research question and understand the available data source."
  },
  {
    "objectID": "people/mark.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-to-yourself-as-a-student",
    "href": "people/mark.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-to-yourself-as-a-student",
    "title": "Mark Hanly",
    "section": "If you could go back in time, what bit of advice would you give to yourself as a student?",
    "text": "If you could go back in time, what bit of advice would you give to yourself as a student?\nHmm. I studied maths and statistics in a way that was almost entirely chalk-and-talk. I would say, learn the stats software at the same time—that’ll make the theory easier!"
  },
  {
    "objectID": "people/mark.html#who-would-play-you-in-the-biopic-of-your-life",
    "href": "people/mark.html#who-would-play-you-in-the-biopic-of-your-life",
    "title": "Mark Hanly",
    "section": "Who would play you in the biopic of your life?",
    "text": "Who would play you in the biopic of your life?\n\n\n\n\n\nI reckon Simon Pegg could pull off both the look and the sense of affable confusion."
  },
  {
    "objectID": "people/mark.html#footnotes",
    "href": "people/mark.html#footnotes",
    "title": "Mark Hanly",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHanly M, Churches T, Fitzgerald O, Caterson I, MacIntyre CR, Jorm L. Modelling vaccination capacity at mass vaccination hubs and general practice clinics: a simulation study. BMC Health Services Research. 22, 1059 (2022). https://doi.org/10.1186/s12913-022-08447-8↩︎"
  },
  {
    "objectID": "people/marzia.html",
    "href": "people/marzia.html",
    "title": "Marzia Hoque",
    "section": "",
    "text": "Marzia is a Lecturer and convenor on the course HDAT9300 Computing for Health Data Science.  m.hoque_tania@unsw.edu.au"
  },
  {
    "objectID": "people/marzia.html#what-publication-are-you-most-proud-of",
    "href": "people/marzia.html#what-publication-are-you-most-proud-of",
    "title": "Marzia Hoque",
    "section": "What publication are you most proud of?",
    "text": "What publication are you most proud of?\nI firmly believe that the best is yet to come, but if I had to select a publication to highlight, it would be an early result from a case study during my doctoral research titled An Intelligent Mobile-Enabled Expert System for Tuberculosis Disease Diagnosis in Real-Time.1 This paper focuses on the development of an intelligent, user-friendly, and cost-effective Tuberculosis antigen-specific antibody detection tool. It not only secured a place in a top-tier journal on Expert Systems but also garnered some media attention. What truly made it memorable was when the Stop TB program retweeted it. I can still vividly recall how that tweet made my day."
  },
  {
    "objectID": "people/marzia.html#whats-the-most-important-take-home-message-from-your-course",
    "href": "people/marzia.html#whats-the-most-important-take-home-message-from-your-course",
    "title": "Marzia Hoque",
    "section": "What’s the most important take home message from your course?",
    "text": "What’s the most important take home message from your course?\nAs a recent addition to the HDAT9300 team, I would emphasise the importance of building a strong foundation in at least one programming language before venturing into data science. Consider it a gradual process and remember that continuous learning is vital in this field. The more you immerse yourself in the course, the more data magic you will wield."
  },
  {
    "objectID": "people/marzia.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-to-yourself-as-a-student",
    "href": "people/marzia.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-to-yourself-as-a-student",
    "title": "Marzia Hoque",
    "section": "If you could go back in time, what bit of advice would you give to yourself as a student?",
    "text": "If you could go back in time, what bit of advice would you give to yourself as a student?\nI would softly convey to my younger self, ‘Establish a robust network of peers, professors, and industry professionals from an early stage. Attend conferences, participate in online forums, and engage in discussions with experts. Your network can be your hidden superpower for collaborations and knowledge sharing.’"
  },
  {
    "objectID": "people/marzia.html#who-would-play-you-in-the-biopic-of-your-life",
    "href": "people/marzia.html#who-would-play-you-in-the-biopic-of-your-life",
    "title": "Marzia Hoque",
    "section": "Who would play you in the biopic of your life?",
    "text": "Who would play you in the biopic of your life?\nAlthough I am not enthusiastic about a biopic, I might entertain the idea of a best-selling novel capturing my life’s adventures!"
  },
  {
    "objectID": "people/marzia.html#footnotes",
    "href": "people/marzia.html#footnotes",
    "title": "Marzia Hoque",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nShabut, A. M., Tania, M. H., Lwin, K. T., Evans, B. A., Yusof, N. A., Abu-Hassan, K. J., & Hossain, M. A. (2018). An intelligent mobile-enabled expert system for tuberculosis disease diagnosis in real time. Expert Systems with Applications, 114, 65-77. doi.org/10.1016/j.eswa.2018.07.014↩︎"
  },
  {
    "objectID": "people/tim.html",
    "href": "people/tim.html",
    "title": "Tim Churches",
    "section": "",
    "text": "Tim Churches as he used to look, which is how he still imagines himself to look now…\n\n\n\n\n\n\nTim Churches as he actually looks now…\n\n\n\nTim is the convenor and principle lecturer on the course HDAT9800 Health Data Visualisation and Communication.  timothy.churches@unsw.edu.au"
  },
  {
    "objectID": "people/tim.html#background",
    "href": "people/tim.html#background",
    "title": "Tim Churches",
    "section": "Background",
    "text": "Background\nDr Tim Churches is a medically-trained epidemiologist and health data scientist with experience in public health informatics in both government and academic roles. He is a Senior Research Fellow at UNSW South Western Sydney Clinical School and the Ingham Institute for Applied Medical Research. His current interests include the use of machine learning in causal estimation, reproducible research methods and teaching health data science. He is the author of several open-source R and Python packages."
  },
  {
    "objectID": "people/tim.html#what-publication-are-you-most-proud-of",
    "href": "people/tim.html#what-publication-are-you-most-proud-of",
    "title": "Tim Churches",
    "section": "What publication are you most proud of?",
    "text": "What publication are you most proud of?\nI think a paper I wrote in 2001 about a novel, column-oriented, set-theoretic framework for rapid exploratory analysis of very large datasets in real-time. At that time, memory (RAM) was limited and expensive, and disc storage was mechanical and slow. Real-time exploration of larger datasets that would not fit in memory (RAM) was not really feasible. I developed a method of pre-computing ordered inverted indices for every column in a dataset, memory-mapping stored versions of these on disc, and then using set operations on those to rapidly subset and cross-tabulate (or visualise) the data in a fraction of a second, much faster than traditional database technologies. The software was released as an open-source package. It had very little impact on anything, although it was used inside NSW Ministry of Health to examine communicable disease and emergency department public health surveillance data for some time. Nonetheless, it was a clever approach, it worked well and both the idea and its implementation (in Python and C) was developed entirely by me.\nChurches T. Exploratory data analysis using set operations and ordinal mapping. Comput Methods Programs Biomed. 2003 May;71(1):11-23. doi: 10.1016/s0169-2607(02)00057-3. PMID: 12725961."
  },
  {
    "objectID": "people/tim.html#whats-the-most-important-take-home-message-from-your-course",
    "href": "people/tim.html#whats-the-most-important-take-home-message-from-your-course",
    "title": "Tim Churches",
    "section": "What’s the most important take home message from your course?",
    "text": "What’s the most important take home message from your course?\nI designed the HDAT9800 Visualisation and Communication of Health Data course with my colleague Dr James Farrow (who is a computer scientist) with goal of equiping students with the skills requird to explore and visualise real-world data, which is often messy, complex and large. More importantly, the course is intended to give students the confidence to explore new methods and software packages (and even write their own), recognising that data science in general is a very fast-moving field, and constant curiosity and exploration of new methods is an essential part of becoming a successful data scientist. Stay curious, and set aside time each week just to play with new methods and packages!"
  },
  {
    "objectID": "people/tim.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-to-yourself-as-a-student",
    "href": "people/tim.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-to-yourself-as-a-student",
    "title": "Tim Churches",
    "section": "If you could go back in time, what bit of advice would you give to yourself as a student?",
    "text": "If you could go back in time, what bit of advice would you give to yourself as a student?\nFind a key textbook in each domain and read it cover-to-cover, possibly several times. It will stick with you for the rest of your life."
  },
  {
    "objectID": "people/tim.html#who-would-play-you-in-the-biopic-of-your-life",
    "href": "people/tim.html#who-would-play-you-in-the-biopic-of-your-life",
    "title": "Tim Churches",
    "section": "Who would play you in the biopic of your life?",
    "text": "Who would play you in the biopic of your life?\n\nI think Bernard Hill, who played the lazy, shambling, reprobate but nonetheless charming coroner, Madgett, in Peter Greenaway’s sublime film Drowning by Numbers, could nicely play lazy, shambling, reprobate but nonetheless charming me."
  },
  {
    "objectID": "people/and.html",
    "href": "people/and.html",
    "title": "Andrew Blance",
    "section": "",
    "text": "Andrew convenes and lectures on several courses, including HDAT9200 Statistical Foundations, HDAT9300 Computing and HDAT9910 Capstone.   a.blance@unsw.edu.au"
  },
  {
    "objectID": "people/and.html#what-publication-are-you-most-proud-of",
    "href": "people/and.html#what-publication-are-you-most-proud-of",
    "title": "Andrew Blance",
    "section": "What publication are you most proud of?",
    "text": "What publication are you most proud of?\nA multilevel modelling solution to mathematical coupling1 What I particularly like about this paper, is that it demonstrates in simple terms a statistical paradox that often hides in plain sight, illustrated for a real world use case (Guided Tissue Regeneration). The proposed methodological solution is both elegant in its design and fully flexible in allowing expansion to model more complex scenarios. Implicit in the paper, is the need for carefully considered ‘meaning making’ whenever investigating casual links."
  },
  {
    "objectID": "people/and.html#whats-the-most-important-take-home-message-from-your-course",
    "href": "people/and.html#whats-the-most-important-take-home-message-from-your-course",
    "title": "Andrew Blance",
    "section": "What’s the most important take home message from your course?",
    "text": "What’s the most important take home message from your course?\nStatistical Thinking! The ‘Art’ needs to work in synergy with the ‘Science’. In other words, one needs to go beyond algorithmic application/processing in order for ‘meaning making’ to happen. Oh, and reflection. Reflection is one of the most powerful tools we have in learning."
  },
  {
    "objectID": "people/and.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-to-yourself-as-a-student",
    "href": "people/and.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-to-yourself-as-a-student",
    "title": "Andrew Blance",
    "section": "If you could go back in time, what bit of advice would you give to yourself as a student?",
    "text": "If you could go back in time, what bit of advice would you give to yourself as a student?\nConsider the pay scales offered by Industry!"
  },
  {
    "objectID": "people/and.html#who-would-play-you-in-the-biopic-of-your-life",
    "href": "people/and.html#who-would-play-you-in-the-biopic-of-your-life",
    "title": "Andrew Blance",
    "section": "Who would play you in the biopic of your life?",
    "text": "Who would play you in the biopic of your life?\n\n\n\n\n\nTom Selleck!"
  },
  {
    "objectID": "people/and.html#footnotes",
    "href": "people/and.html#footnotes",
    "title": "Andrew Blance",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBlance A, Tu YK, Gilthorpe MS. A multilevel modelling solution to mathematical coupling. Statistical Methods in Medical Research. 2005 Dec;14(6):553-65. http://doi.org/10.1191/0962280205sm418oa↩︎"
  },
  {
    "objectID": "people.html",
    "href": "people.html",
    "title": "Meet the teaching team",
    "section": "",
    "text": "Andrew Blance\n\n\nSenior Lecturer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlanca Gallego Luxan\n\n\nAssociate Professor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHeidi Welberry\n\n\nResearch Fellow\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMark Hanly\n\n\nSenior Lecturer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMarzia Hoque\n\n\nLecturer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOscar Perez Concha\n\n\nSenior Lecturer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSanja Lujic\n\n\nSenior Lecturer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTim Churches\n\n\nHealth Data Scientist\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "How do I enrol into courses?\n\n\n\n\n\nIf you are enroling for the first time please visit How to Enrol as a New Student at UNSW.\nFor annual enrolment and class registration please visit Annual Enrolment page\nIf you are enrolling in elective courses for MScHDS degree and are getting a message about not meeting enrolment requirements, please email MScHDS@unsw.edu.au and the Program Director will provide you with supporting information.\n\n\n\n\n\n\n\n\n\nWho do I contact if I need help?\n\n\n\n\n\nNucleus – Student Hub – provides centralised systems to help with enrolment, internal program transfer (IPT), program progression check, recognition of prior learning (RPL), Early Exit/Graduation request, late enrolment, overload studies, requisite waiver, review of results, fee remission, program leave, deferral, discontinuation, confirmation of enrolment, reduce study load. Other questions about the program, choice of electives and other queries or concerns can be emailed to the Program Director at MScHDS@unsw.edu.au or their email address.\n\n\n\n\n\n\n\n\n\nWhat does articulation mean?\n\n\n\n\n\nHealth Data science programs of Graduate Certificate Graduate Diploma Masters Masters with Extension can articulate with each other. This means students in the Graduate Certificate can transfer to the Graduate Diploma or the Masters degree, or vice versa (exit with a lower award).\nArticulation pathway towards a higher degree: GCer (7372) &gt; GDip (5372) &gt; MSc (9372) &gt; MSc (Ext) (9373)\nExit points: MSc (Ext) (9373) &gt; MSc (9372) &gt; GDip (5372) &gt; GCer (7372)\n\n\n\n\n\n\n\n\n\nWhat is the difference between dissertation and capstone/elective pathway?\n\n\n\n\n\nThe MSc Health Data Science offers a choice between a 24 UoC workplace/internship research dissertation (full-time or part-time options) or a 6 UoC capstone project plus 18 UoC electives (from a selection of over 20 courses – see Handbook). The choice of a pathway depends on your desire to work independently on a larger project (dissertation) or a more pre-defined research project (capstone). Students wishing to progress towards a PhD are encouraged to enrol in a dissertation pathway.\nGaining a place in a dissertation is competitive and at the discretion of both the course convenor/s and the supervisor offering a particular dissertation project.\nIn order to enrol into dissertation subjects (HDAT9900/9901/9902) you will need to complete the core courses of the Grad Certificate and Grad Diploma of Health Data Science or have been granted an exemption for courses by the MSc program authority. For more information see Team HDS space and select 3. For students considering a dissertation.\n\n\n\n\n\n\n\n\n\nWhats the difference between full-time vs part time study load?\n\n\n\n\n\nAll courses are measured in whole Units Of Credit (UOC). Full-time enrolment for one year is defined as 48 UOC with at least one enrolment in each term. Domestic students wishing to be considered full-time need to enrol in a minimum of 12 UOC each term (i.e., 2 subjects), or 36 UOC across three standard terms with at least one course enrolment in each term.\n\n\n\n\n\n\n\n\n\nWhich courses are offered when?\n\n\n\n\n\nThe majority of HDAT core courses run twice per year, except for HDAT9500 and HDAT9800. Check out the calendar page to see the course running order for upcoming terms\n\n\n\n\n\n\n\n\n\nHow do I apply for program leave?\n\n\n\n\n\nYou can apply for program leave if you want to take a leave of absence from your program of up to 1 year and come back to your studies after taking leave. undergraduate or postgraduate students. It is available to international students with certain Program leave is for enrolled domestic conditions. For more information visit the Program Leave page."
  },
  {
    "objectID": "faq.html#program-level",
    "href": "faq.html#program-level",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "How do I enrol into courses?\n\n\n\n\n\nIf you are enroling for the first time please visit How to Enrol as a New Student at UNSW.\nFor annual enrolment and class registration please visit Annual Enrolment page\nIf you are enrolling in elective courses for MScHDS degree and are getting a message about not meeting enrolment requirements, please email MScHDS@unsw.edu.au and the Program Director will provide you with supporting information.\n\n\n\n\n\n\n\n\n\nWho do I contact if I need help?\n\n\n\n\n\nNucleus – Student Hub – provides centralised systems to help with enrolment, internal program transfer (IPT), program progression check, recognition of prior learning (RPL), Early Exit/Graduation request, late enrolment, overload studies, requisite waiver, review of results, fee remission, program leave, deferral, discontinuation, confirmation of enrolment, reduce study load. Other questions about the program, choice of electives and other queries or concerns can be emailed to the Program Director at MScHDS@unsw.edu.au or their email address.\n\n\n\n\n\n\n\n\n\nWhat does articulation mean?\n\n\n\n\n\nHealth Data science programs of Graduate Certificate Graduate Diploma Masters Masters with Extension can articulate with each other. This means students in the Graduate Certificate can transfer to the Graduate Diploma or the Masters degree, or vice versa (exit with a lower award).\nArticulation pathway towards a higher degree: GCer (7372) &gt; GDip (5372) &gt; MSc (9372) &gt; MSc (Ext) (9373)\nExit points: MSc (Ext) (9373) &gt; MSc (9372) &gt; GDip (5372) &gt; GCer (7372)\n\n\n\n\n\n\n\n\n\nWhat is the difference between dissertation and capstone/elective pathway?\n\n\n\n\n\nThe MSc Health Data Science offers a choice between a 24 UoC workplace/internship research dissertation (full-time or part-time options) or a 6 UoC capstone project plus 18 UoC electives (from a selection of over 20 courses – see Handbook). The choice of a pathway depends on your desire to work independently on a larger project (dissertation) or a more pre-defined research project (capstone). Students wishing to progress towards a PhD are encouraged to enrol in a dissertation pathway.\nGaining a place in a dissertation is competitive and at the discretion of both the course convenor/s and the supervisor offering a particular dissertation project.\nIn order to enrol into dissertation subjects (HDAT9900/9901/9902) you will need to complete the core courses of the Grad Certificate and Grad Diploma of Health Data Science or have been granted an exemption for courses by the MSc program authority. For more information see Team HDS space and select 3. For students considering a dissertation.\n\n\n\n\n\n\n\n\n\nWhats the difference between full-time vs part time study load?\n\n\n\n\n\nAll courses are measured in whole Units Of Credit (UOC). Full-time enrolment for one year is defined as 48 UOC with at least one enrolment in each term. Domestic students wishing to be considered full-time need to enrol in a minimum of 12 UOC each term (i.e., 2 subjects), or 36 UOC across three standard terms with at least one course enrolment in each term.\n\n\n\n\n\n\n\n\n\nWhich courses are offered when?\n\n\n\n\n\nThe majority of HDAT core courses run twice per year, except for HDAT9500 and HDAT9800. Check out the calendar page to see the course running order for upcoming terms\n\n\n\n\n\n\n\n\n\nHow do I apply for program leave?\n\n\n\n\n\nYou can apply for program leave if you want to take a leave of absence from your program of up to 1 year and come back to your studies after taking leave. undergraduate or postgraduate students. It is available to international students with certain Program leave is for enrolled domestic conditions. For more information visit the Program Leave page."
  },
  {
    "objectID": "faq.html#course-level",
    "href": "faq.html#course-level",
    "title": "Frequently Asked Questions",
    "section": "Course Level",
    "text": "Course Level\n\n\n\n\n\n\nWhen can I access course materials?\n\n\n\n\n\nCourse materials are hosted on Open Learning, class Teams spaces or class websites, depending on the course. See the software and platforms page for more detail. Access to Open Learning will be either via Moodle or Teams. Yours course convenors will provide you with more information. All HDAT courses go ‘live’ by Friday 5pm of O-week (Friday prior to the semester start date). Materials are released on a weekly basis thereafter.\n\n\n\n\n\n\n\n\n\nHow can I access course materials?\n\n\n\n\n\nThis will depend on the course so please follow the instructions from your convenors. They will make an announcement via Teams and/or Moodle about the release of weekly materials. Check out the software and platforms page to see the platforms used for each course.\n\n\n\n\n\n\n\n\n\nHow many hours per week should I dedicate to my studies?\n\n\n\n\n\nThe normal workload expectations of a student are approximately 25 hours per term for each UOC (150 hours total for 6 UOC course), including class contact hours, other learning activities, preparation and time spent on all assessable work.\n\n\n\n\n\n\n\n\n\nWhen can I drop a course without financial penalty?\n\n\n\n\n\nCensus date is Sunday of Week 4 each term, and you can drop courses without financial or academic penalty before then. Key dates can be found at UNSW Key Dates for Students | UNSW Current Students.\n\n\n\n\n\n\n\n\n\nWhen can I expect feedback on my assessment?\n\n\n\n\n\nAssessment tasks completed within the teaching period of a course, other than a final assessment, will be assessed and students provided with feedback, within 10 working days of submission, under normal circumstances.\n\n\n\n\n\n\n\n\n\nHow do I apply for special consideration (SC)?\n\n\n\n\n\nYou are encouraged to apply for SC when your circumstances are short-term, serious, and unavoidable. They must be circumstances that:\n\nWere unexpected and beyond your control and;\nCaused disturbance to academic work by a substantial degree and;\nCould not have reasonably been anticipated, avoided or guarded against by you and either;\n\nOccurred during a critical study or assessment period and lasted at least 3 consecutive days or a total of 5 days within the critical study period or;\nPrevented the ability to complete, attend or submit an assessment task for a specific date (e.g., final exam, in class test/quiz, in class presentation)\n\n\nYou can read more about the special consideration process and how to apply on the UNSW Special Consideration page.\n\n\n\n\n\n\n\n\n\nWho do I contact if I need help?\n\n\n\n\n\nFor course related questions please contact your course convenor in the first instance. You can also email the Program Director using their email (s.lujic@unsw.edu.au), or email our shared health data science email MScHDS@unsw.edu.au."
  },
  {
    "objectID": "faq.html#general",
    "href": "faq.html#general",
    "title": "Frequently Asked Questions",
    "section": "General",
    "text": "General\n\n\n\n\n\n\nWhere to find us\n\n\n\n\n\nAll our teaching staff are located at the Centre for Big Data Research in Health, Faculty of Medicine. Physical location is: AGSM Building (G27), Gate 11, Botany St, UNSW Sydney Campus, Kensington NSW 2052\n\n\n\n\n\n\ngoogle map codes for website\n\n\n\n\n\n\n\n\n\n\n\n\nHow large is the HDS cohort?\n\n\n\n\n\nWe currently have around 150 students across various stage of their health data science degree.\n\n\n\n\n\n\n\n\n\nWhere is good to eat and drink on campus?\n\n\n\n\n\n\nFor coffee\n\nOn upper campus: The Little Marionette, XS Espresso, The Courtyard Café, Caffe Brioso\nOn middle campus: Penny Lane, Plume Café\n\n\n\nFor food\n\nOn upper campus: Mathews food court (including Stockmarket for salads, Sushi Roll, Laksa Delight, Classic Kebab, Gradueat), Pho House, Courtyard Café at AGSM\nOn lower campus: University Terrace (Mamak Village, Stellini Pasta Bar, Guzman Y Gomez, Yallah), Roundhouse, Thoughtful foods\n\nView on map\n\n\n\n\n\n\n\n\n\n\nWho do I contact if I need help?\n\n\n\n\n\nUNSW has a rage of support services available for students. Visit the Student Support website to find a list of key services and links on how to access them."
  },
  {
    "objectID": "posts/2023-01-13-sas-cortex/index.html",
    "href": "posts/2023-01-13-sas-cortex/index.html",
    "title": "Winning the SAS Cortex Analytics Simulation Challenge",
    "section": "",
    "text": "mamiya_adachi@yahoo.co.jp\n\n\n https://www.linkedin.com/in/mamiyaad/\n\n\n\n\n\n\nManny Adachi is an aspiring data scientist from Japan in the Master’s program in Health Data Science. His interests are in motorcycle touring, traveling, and of course data science!!\nThis is a short post about my participation in the SAS Cortex Analytics Simulation 5 Day Challenge (hereafter, Cortex) in April 2022. Luckily, I became the 1st place winner in the competition. It is not a direct application of what we have learned in the HDS program to the formal job scene. However, I think it can still provide you some idea of how much knowledge we can use outside the classes. Please also see the post by Lucia Biasi from SAS Australia for some details of the interview on me about my experience.\n\nWhat is Cortex?\nCortex is an analytics simulation game developed by SAS and HEC Montreal. It tests participants’ predictive modeling skills using a real-life problem as they compete against peers. The game scenario was to help a fictitious non-profit organization which needed to figure out who to contact from a list of potential donors. Using SAS Enterprise Miner, participants built a predictive model and generated a contact list to maximise the surplus amount (i.e. donation amount – cost of contacting). For the duration of Cortex, participants were allowed to revise the contact list up to around 30 times. The prior versions were also maintained in the system so participants are able to select their best contact list later on.\n\n\nWhat did I learn through Cortex?\nIt was my first and fun experience using a GUI (Graphic User Interface)-based tool to construct a pipeline of data cleaning, exploratory data analysis, modeling, and testing. The Cortex GUI allows users to interact with tools through icons, menus, and mouse. Therefore, it is more intuitive for the uses to have a control of the tool than entirely coding the required tasks. Although the tools we used in the school assignments such as Jupyter Notebook, R Studio, and SAS Studio have GUI components, with Cortex we could complete the tasks mostly without coding. It was, of course, way more convenient than mostly coding like we did for the school assignments. I could spend more time on thinking how to optimize the surplus amount (e.g., comparing the result using different base models and (hyper)parameters, how to minimize overfitting, deciding where to cut the list from the model (*cutting was done manually and still acceptable)).\n\n\n\nA pipeline diagram constructed on Cortex by Harry Ngo, a participant back in 2020. My final pipeline and final model were different from the above, but it should provide you a sufficient visualization of how things went\n\n\nSo, am I here just as a shill and say how brilliant the SAS platform was? No (although I know that I am already helping them…). Instead, I really want to emphasize that what ends up making the difference sometimes are something beyond knowing how to code a fancy and complex statistical or machine learning model. In my case during Cortex, what helped me were (1) the base knowledge from HDS about the characteristics of each machine learning model, (2) how to read the training / validation score graphs, (3) the strategy of submission time to minimize the other competitors’ time to revise their lists (i.e., submitting the best list when the game was approaching to the end and other competitors appeared satisfied with the moderate but not the best list), and (4) the persistency until the very last minute of the game.\nHere is a little more comment about (1). Although I cannot mention which model I used for my final contact list, I can say it helped me avoid overfitting my model and possibly bluff the other competitors with the list from the overfit model. It was one example of how we can apply our knowledge from HDS program to strategize our action.\n Learn more about the Cortex analytics simulation game at www.sas.com/cortex\n\n\nWinning the game, then what?\nAs the winner, I was offered the badge and 4-week internship at SAS Australia. During the internship I was able to (1) connect with SAS members in various teams such as technical support, pre / post-sales, delivery consulting, and customer success and learn about their roles and offerings, (2) access the study materials for SAS Viya programming associate exam for free, and (3) earn the certificate after passing the exam. Beside the time to connect with SAS members, I spent the majority of time studying for the exam, so it is indeed a large part of what I have learned through the internship. One thing I hoped to do was to practice how to integrate the models that we build with external sources such as Python or R. The integration is one of the key highlights on SAS Viya’s capability.\nI have to confess that I did not know much about the company and what they offer until several days after my internship started. (Please don’t blame me on this since obviously I got this internship opportunity without any interviews). In short, they offer the solutions which support the operations in the whole analytics life cycle, and they have been the long-established and leading vendor of the statistical data analysis software for various sectors such as government / public service, healthcare, banking / finance, and academia. You can also learn more about SAS from a post by Emmett Boudreau.\n\n\nConclusion\nI definitely recommend other students to participate in the Cortex competition hosted by SAS (or any hackathon events). It gives us not only the data science experience outside of class, but also the chance to have our hands on the analytics platforms used in the industry and connect with other participants and sometimes people from industry."
  },
  {
    "objectID": "posts/2023-09-11-applying-literate-programming-techniques-in-the-workplace/index.html",
    "href": "posts/2023-09-11-applying-literate-programming-techniques-in-the-workplace/index.html",
    "title": "Applying literate programming techniques in the workplace",
    "section": "",
    "text": "Calum.Nicholson@hri.org.au\n\n\n hri.org.au/our-research/clinical-research/mr-calum-nicholson\n\n\n linkedin.com/in/calum-nicholson-13b256171\n\n\n\n\n\n\n\n\nCalum has been working with the Heart Research Institute since 2018 and he is the National Coordinator for an Australia-wide congenital heart disease (CHD) registry.\nCalum completed the MSc Health Data Science in 2021. His dissertation used geographical information and analysis techniques to assist with service delivery planning for adults with Congenital Heart Disease an was published in PLOS Digital Health.\n\nThe need for literate programming\nWorking as data scientists, our analyses are useless if they cannot be communicated with our collaborators and audiences. Especially when working with topic area specialists such as clinicians, public health experts or clinical researchers, presenting the results of our data analysis is essential. Literate programming techniques are tools that allow for the combination of conventional word processing with code for data analysis. These tools have fast become one of the most useful tools that I was taught during my time completing the Master of Health Data Science with the Centre for Big Data Research in Health. Of course, you still need the key skills of a data scientist—data management, statistics, and visualisation—otherwise there would be nothing to include in a report! However, working with people who do not have the access to the analytic software that you might use means that we need to be able to take our analyses out of these systems so that other people can engage with our work.\nMarkdown is a common form of implementing a literature programming technique. It is a mark-up language that is used to format text documents. Unlike Microsoft Word, which is a WYSIWYG (/ˈwɪziwɪɡ/ WIZ-ee-wig, i.e. what you see is what you get!) editor, where changes are to text formatting are seen immediately, Markdown uses specific syntax to create formatted text. This does require learning some of the markdown language, but you can mostly get by with knowing a few basics such as headings, lists, and bold and italic text. There are many different tools that combine markdown language with code, Jupyter Notebook is a common one that works with many different coding languages. My experience is mostly with R Markdown from R Studio, which is an excellent tool for literate programming.\nI work for the Heart Research Institute, coordinating a project that is developing a Bi-National Registry for Congenital Heart Disease in Australia and New Zealand. In this role we have moved through data collection, cleaning, and analysis phases. In all these areas, using literate programming tools to generate reports have become a key part of my workflows. I am often collaborating with clinical staff, often cardiologists, nurses, and neuropsychologists, to produce various outputs and these outputs are always a HTML report using R Markdown.\n\n\nData Collection Reports: did I receive that data that I think I did?\nData collection for our registry involves receiving extracts for clinical data sources, often with hundreds of thousands of records. It is important to make sure that the data that we receive is what was intended to be sent. To aid these processes, I have developed data collection reports using R Markdown. These simply overview everything that was received, with some simple exploratory data analysis. These reports often go back to data managers and clinicians and provide a very useful sanity check that can identify simple mistakes early in the process.\n\nOutputCode\n\n\n\n\n\nGenerating consort diagrams with ggconsort A flow diagram for patient selection into the ACHD registry. Toggle to the code tab to see the underlying code.\n\n\n\n\nFirst a “Study Cohort” is generated. dplyr verbs can be used to filter the cohort that will appear in the flowchart. Second, the boxes and arrows are drawn and plotted with ggplot.\n\nstudy_cohorts &lt;- el.sample %&gt;%\n                  cohort_start(\"Assessed for eligibility\") %&gt;%\n                  # Define cohorts using named expressions\n                  cohort_define(\n                    # Patient with missing diagnosis or procedure codes\n                    missing = .full %&gt;% filter(!has_dx & !has_proc), \n                    # only patients with diagnosis or procedure considered\n                    considered = .full %&gt;% filter(has_dx | has_proc),\n                    # patients without congential heart disease\n                    ineligibile = .full %&gt;% filter(!el_final & (has_dx | has_proc)),\n                    # patients with congential Heart Disease\n                    eligibile = .full %&gt;% filter(el_final)) %&gt;%\n                  # Provide text table for cohorts\n                  cohort_label(\n                    missing = \"No Diagnosis or Procedure\",\n                    considered = \"Patients considered for eligibility\",\n                    ineligibile = \"Ineligibile Patients\",\n                    eligibile = \"Eligibile Patients\")\n\nstudy_consort &lt;- study_cohorts %&gt;% \n                  # Add the boxes\n                  consort_box_add(\n                    \"full\", 0, 50, cohort_count_adorn(study_cohorts, .full)) %&gt;%\n                  consort_box_add(\n                    \"considered\", 0, 30, cohort_count_adorn(study_cohorts, considered)) %&gt;%\n                  consort_box_add(\n                    \"eligibile\", 0, 10, cohort_count_adorn(study_cohorts, eligibile)) %&gt;%\n                  consort_box_add(\n                    \"missing\", 5, 40, cohort_count_adorn(study_cohorts, missing)) %&gt;%\n                  consort_box_add(\n                    \"ineligibile\", 5, 20, cohort_count_adorn(study_cohorts, ineligibile)) %&gt;%\n                  # Add the arrows\n                  consort_arrow_add(\n                    start = \"full\", start_side = \"bottom\",\n                    end = \"considered\", end_side = \"top\") %&gt;%\n                  consort_arrow_add(\n                    start = \"considered\", start_side = \"bottom\",\n                    end = \"eligibile\", end_side = \"top\") %&gt;%\n                  consort_arrow_add(\n                    end = \"missing\", end_side = \"left\", start_x = 0, start_y = 40) %&gt;%\n                  consort_arrow_add(\n                    end = \"ineligibile\", end_side = \"left\", start_x = 0, start_y = 20) %&gt;% \n              # Plot with ggplot\n              ggplot() +\n              geom_consort() +\n              theme_consort(margin_h = 15, margin_v = 1)\n\nstudy_consort\n\n\n\n\nA flowchart is a very useful tool for communicating the data collection process and how an eligible population was determined. This has always been difficult to implement in R and has usually required some manual development in a Microsoft Office application. However, I have recently discovered the ggconsort package that is great for making Consort-Style flowchart. This package can create simple consort diagrams that are perfect for demonstrating how a target population was reached. It uses very familiar dplyr and ggplot2 workflows that make it quite easy to pick up for those who are already familiar with the tidyverse.\n\n\nData Analysis: collaborating with topic area specialists.\nRecently, I have been working with neuropsychologists to analyse data in preparation for manuscripts. Unsurprisingly, I know very little about neuropsychology and the neuropsychologists have never used R before! Using literate programming as an iterative process to complete data analysis for a manuscript can really help bridge the gap between disciplines. Ideally, I would want to hand over my analyses with enough clarity that my collaborators can assess my methodologies from their expert perspectives and then write up their results and methods sections using only my reports. This requires not only providing the analysis but including some notes and comments about methodology used for cohort selection and statistical analysis. Since literate programming allows you to write prose alongside your code, it provides a great process for clearing writing out your methods right alongside the analysis and results. You can provide exactly what you think should be included in a manuscript to describe your analysis and your collaborators won’t have to try decipher your code to understand what you are doing.\n\nOutputCode\n\n\n\n\n\nCreating Summary Tables with qrwraps2 Summary statistics for patients who had completed a DASS-21 survey (example from a recent poster). Toggle to the code tab to see the underlying code.\n\n\n\n\nThe code below uses the summary_table() function from the qwraps package to create a nice summary table. The template is applied to the whole dataset, then stratified by disease complexity (using dyplr::group_by()). We can then add these two tables together with cbind() to create the final table.\n\noptions(qwraps_markup = \"markdown\")\n\n# Create Table Template for DASS-21 Summary\ndass_level_summary &lt;-\n  list(\"Depression\" =\n         list(\"Normal\" = ~ n_perc0(dass_dep_level_clean == \"Normal\"),\n              \"Mild\" = ~ n_perc0(dass_dep_level_clean == \"Mild\"),\n              \"Moderate\" = ~ n_perc0(dass_dep_level_clean == \"Moderate\"),\n              \"Severe\" = ~ n_perc0(dass_dep_level_clean == \"Severe\"),\n              \"Extemely Severe\" = ~ n_perc0(dass_dep_level_clean == \"Extemely Severe\"),\n              ),\n       \"Anxiety\" =\n         list(\"Normal\" = ~ n_perc0(dass_anx_level_clean == \"Normal\"),\n              \"Mild\" = ~ n_perc0(dass_anx_level_clean == \"Mild\"),\n              \"Moderate\" = ~ n_perc0(dass_anx_level_clean == \"Moderate\"),\n              \"Severe\" = ~ n_perc0(dass_anx_level_clean == \"Severe\"),\n              \"Extemely Severe\" = ~ n_perc0(dass_anx_level_clean == \"Extemely Severe\"),\n              ),\n       \"Stress\" = \n         list(\"Normal\" = ~ n_perc0(dass_stress_level_clean == \"Normal\"),\n              \"Mild\" = ~ n_perc0(dass_stress_level_clean == \"Mild\"),\n              \"Moderate\" = ~ n_perc0(dass_stress_level_clean == \"Moderate\"),\n              \"Severe\" = ~ n_perc0(dass_stress_level_clean == \"Severe\"),\n              \"Extemely Severe\" = ~ n_perc0(dass_stress_level_clean == \"Extemely Severe\"),\n              )\n       )\n\n# Summary Table for whole dataset\ndass.level.whole &lt;- summary_table(poster.population, dass_level_summary)\n\n# Summary table stratified by complexity\ndass.level.complexity &lt;- summary_table(dyplr::group_by(poster.population, chd_complexity), dass_level_summary)\n\n# Combine both tables\ndass.level &lt;- cbind(dass.level.whole, dass.level.complexity)\n\n# Print table with title\nprint(dass.level,\n      rtitle = \"DASS-21 Level - Summary Statistics\",\n      cnames( c(paste(\"All (N -\", poster.population %&gt;% nrow, \")\", sep = \"\"),\n                paste(\"Mild (N -\", poster.population %&gt;% filter(chd_complexity = \"Mild\") %&gt;% nrow, \")\", sep = \"\"),\n                paste(\"Moderate (N -\", poster.population %&gt;% filter(chd_complexity = \"Moderate\") %&gt;% nrow, \")\", sep = \"\"),\n                paste(\"Severe (N -\", poster.population %&gt;% filter(chd_complexity = \"Severe\") %&gt;% nrow, \")\", sep = \"\")\n                )\n              )\n)\n\n\n\n\nThese reports are also a great help to communicate the results of your analysis since we can include direct output from the analysis, figures, tables, and comments that help to interpret the results. Of these outputs, creating publication-ready tables has always been the most challenging to implement in the flow of an R Markdown report. There are packages like knitr and kableExtra that can format tables nicely, but I have found that creating the tables to go into this format can often be difficult and time consuming. I have recently found a great package called qwraps2 that has a lot of functions for reproducible reporting and summary_table() is probably my new favourite. It allows you to create a template table format that can be applied to your data. This allows for a very flexible and reproducible way to create summary tables of your data. It is especially useful for providing a demographic overview of your study population.\n\n\nWhere to start with literate programming?\nTo get started with literate programming in R check out the RMarkdown website at rmarkdown.rstudio.com. You’ll find step-by-step instructions to get started as well as a gallery of examples with heaps of inspiration! The qwraps2 package has a detailed vignette showing how to build a variety of summary tables. Python users can check out Jupyter Notebooks from the Jupyter community."
  },
  {
    "objectID": "posts/2023-06-02-hds-datathon/index.html",
    "href": "posts/2023-06-02-hds-datathon/index.html",
    "title": "CBDRH Datathon: a taste of a (real) synthetic dataset",
    "section": "",
    "text": "cevalierre@gmail.com"
  },
  {
    "objectID": "posts/2023-06-02-hds-datathon/index.html#footnotes",
    "href": "posts/2023-06-02-hds-datathon/index.html#footnotes",
    "title": "CBDRH Datathon: a taste of a (real) synthetic dataset",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nKuo NI-H, Garcia F, Sönnerborg A, Zazzi M, Böhm M, Kaiser R, Polizzotto M, Jorm L, Barbieri S. Generating Synthetic Clinical Data that Capture Class Imbalanced Distributions with Generative Adversarial Networks: Example using Antiretroviral Therapy for HIV. Available at: https://arxiv.org/abs/2208.08655↩︎\nDelpech V. The HIV epidemic: global and United Kingdom trends. Medicine (Abingdon). 2022 Apr;50(4):202-204. doi: 10.1016/j.mpmed.2022.01.002.↩︎\nGonzales A, Guruswamy G, Smith SR. Synthetic data in health care: A narrative review. PLOS Digit Health. 2023 Jan 6;2(1):e0000082. doi: 10.1371/journal.pdig.0000082.↩︎"
  },
  {
    "objectID": "posts/2023-04-02-bridging-the-chasm/index.html",
    "href": "posts/2023-04-02-bridging-the-chasm/index.html",
    "title": "Bridging the chasm of expectations and reality with real-world projects",
    "section": "",
    "text": "danielleritz.shala@health.nsw.gov.au\nWhat makes working in intensive care different? For me, it’s the criticality of time, patient care, communication, technology, and priorities. Working in this type of environment forces people to prioritise ruthlessly and find efficient ways of doing tasks–partly to save time, but mostly to be ready and focused for the next unpredictable certainty (e.g. a baby who starts off crying like a rockstar and shortly turns blue, a toddler who’s woken up thrashing around and removing the breathing tube while the nurse was on break, a massive drop in blood pressure hours after a heart surgery, etc). As I was working clinically, I observed that copying and pasting is used by some clinicians to complete their electronic documentation quicker. Unfortunately, some would inadvertently enter a progress note on the wrong patient’s record, and others would forget to update a copied note with relevant changes in a patient’s status or therapy settings. As I experienced the reality of these risks on the floor, I noted there was a problem. I could see how the scenarios were generally a result of earnest efforts to use technology smartly and more efficiently, however there was also potential for unintended harm.\nI have always been interested in the use (and perhaps misuse and abuse) of technology in healthcare, particularly its implications in real-world settings. I was attending local and international informatics conferences around 2017/18, and was also having informal chats with doctors and nurses about electronic medical record (eMR) documentation and efficiency in general, as I was curious to find out their experiences and perspectives. Through these discussions I realised that while most people assume redundancies, duplications, and copying and pasting happens “a lot” in clinical documentation, there was no measure, nor existing information around it—at least none that I could find in the local, state, or national level. This was another problem I noted. I believe discussions and decisions around eMR documentation and clinical practice would be more productive if guided by both data AND context—two constructs which I think should never be separated, particularly in healthcare. It was then that I became more interested in quantifying text similarity in clinical progress notes, and establishing a baseline measure for it in a local Australian setting.\nAt the time I was working part time as an ICU nurse, and part time as a research intern at the network, and towards the end of the internship, I proposed a research study and applied for grant funding to work on the study. I was also keen to learn new ways to explore and analyse data, and had just started the Health Data Science course at this time, so it was a perfect opportunity to apply university concepts to a project based on real-world experiences. The resulting study, Measuring text similarity and its associated factors in electronic nursing progress notes: A retrospective review1, was published in 2022 in the Journal of Clinical Nursing. The paper is also available in a shorter open access version, titled Need We Say More? Measuring Redundancy in Nursing Progress Notes2 published by the International Medical Informatics Association (IMIA) and IOS Press."
  },
  {
    "objectID": "posts/2023-04-02-bridging-the-chasm/index.html#what-did-i-learn-from-working-on-a-real-world-project",
    "href": "posts/2023-04-02-bridging-the-chasm/index.html#what-did-i-learn-from-working-on-a-real-world-project",
    "title": "Bridging the chasm of expectations and reality with real-world projects",
    "section": "What did I learn from working on a real-world project?",
    "text": "What did I learn from working on a real-world project?\n\nExperience with real eMR data and manipulating messy datasets for a specific clinical context\nFor this study, I was given two separate datasets: one containing patient details, and another containing progress notes. It was quite messy as it contained notes for an entire patient stay, with varying note structures and lengths. At first it may sound fairly straightforward to identify text that has been copied and pasted, and the data scientist in us would be very excited to code some form of regular expressions (regex) or clustering algorithm to help in detecting the notes required—but consider that this is “a step to a step” which could also take time and would need testing depending on your level of programming experience and exposure to the text. In my case, I was early in my HDS programming journey.\nI dedicated a period to run and test the first option, but noticed that there are notes that either get excluded or included which didn’t fit the study criteria. For example, if I filtered just by the category type (e.g. nursing progress note) and location (e.g. ICU), I ended up including notes from specialist nurses who visit ICU patients. Some of them may have a “Clinical Nurse Specialist” title in the system, others may have a “Registered Nurse” title. While some with the title “Registered Nurse” will do a progress note, not all of them will do a shift summary progress note for a patient. Some followed a specific format for writing shift summary notes, but others didn’t. It was definitely interesting for me to see the scenarios and variations of what happens in practice, and how these were reflected in the data!\nOverall, I had to find ways to match the notes and filter down to only what I needed—this was a great way to apply what I knew as a clinician, what I was learning in Python and practically working with Pandas and numpy! I decided not to skip the manual task of annotating the relevant notes and classifying whether they were done in ICU or not. This meant checking over a thousand notes individually, confirming that they were indeed shift summary notes, done by a nurse, and in ICU. Supervised machine learning could be an alternative to this, but for most machine learning tasks, having correctly labelled data or the “ground truth” would be ideal. While this step took considerable time, it was definitely worthwhile, as it has allowed me to understand our practice deeper and learn more about the nuances of clinical text.\n\n\n\nDanielle is a Clinician and Data Scientist with applied experience in the use of health data in clinical, research, and industry settings. (author supplied)\n\n\n\n\nStarting with simple and practical methods to answer a question and fit a defined context\nThere’s a plethora of methods, studies, and repos that can address a question/problem these days (and there’s chatGPT too!). As more and more sophisticated programs and analytical techniques have sprung up in recent years, it’s easy to get excited and carried away by the next shiny library/tool and lose sight of the core question being solved. For me, the true challenge for a data scientist lies in finding the right fit for the problem at hand.\nI read about different ways of calculating similarity—each had its own strengths, limitations, and implications. I tested and compared results across a few methods but found minimal differences in the results. After awhile I took a step back and reflected on the purpose and context of the study: from here, I settled on a method that might give results that are closer to the visual recognition of repetitive text, or mimic the feeling of “I think I’ve read that part!” among clinicians, as this relates more to the broader concerns of cognitive overload, efficiency, and value of text repetition in ICUs.\nAs it was an exploratory study, part of my goal was also to set a foundation that others may build on and contribute to the body of knowledge around the topic of electronic clinical documentation, especially for nurses. There’s lots of room for improving the study, but that in itself is part of the journey and the learning! This makes reflection on real-world findings, evidence-based recommendations, and learning different ways to tackle a question/problem possible.\nKnowing the problem/question, the purpose and context of the work, and resisting the urge to reinvent the wheel is also useful. Where there are existing methods and libraries, build on them and get creative. One may gain theoretical/academic brownie points as with increasing the complexity of a program/solution, but that may also mean that it’s less applicable, reproducible, or practical in a real world setting. Breaking down problems and simplifying solutions are superpowers, and one can build on these skills by reflecting on work and progress regularly.\n\n\nWorking with engaged leaders and supervisors and communicating with other teams to progress goals\nThe endless possibilities of programming may be exciting to us data scientists, but that wouldn’t always translate to another person. Communicating technical concepts to non-technical groups or individuals was perhaps one of the most challenging and rewarding parts of the project for me. This is something that I definitely picked up in the real world, and something that I sought out to do, as I wanted to use my clinical background and early HDS skills to bridge gaps across clinical, technical, and leadership teams.\nLearning to engage with key contacts from other departments is also important in the success of a project. For example, as I was preparing our ethics application, I sought advice from the research and ethics department and clarified points that we were unsure about. I learned a great deal about the process, and their team became acquainted with our project early on. It took a number of back and forth discussions with contacts but in the end, we saved considerable time as our application was approved on first submission. This would not have been possible without my supportive and empowering supervisor who was patient in listening to my ideas, and tremendously helpful in framing and consolidating them for applications and presentations. It’s always helpful to seek and receive feedback, particularly from experts who have already been through a similar process.\nAnother example demonstrating the importance of communication for the project was liaising with the medical records team. The initial dataset supplied to me was very large and didn’t look “right”. You’ll know this as you perform exploratory data analysis and find values that are either out of range or out of the context of your study. While I was excited that I’ve received the data (finally!), I knew I couldn’t use it for preparation and analysis yet, and had to have discussions with the person who extracted the data. Apart from going back to the data request form and project protocol, it was helpful for us to have meetings where we could walk through these together and quickly clarify questions. The extract took more time due to this, but in the end it worked out as the dataset was also halved and more aligned with the study requirements.\nOverall, working on a project based on a real world healthcare setting was a great way for me to apply my domain knowledge as a clinician while refining my skills as a data scientist. I enjoyed the highs and lows of the project—both on the technical and “soft” aspects as it exposed me to a variety of scenarios and unforeseen challenges, and encouraged me to become more adaptable, creative, and focused in my approaches. There are plenty of ideas and ideals we would like translated in the real world, but the cold hard truth is it isn’t as easy as “1,2,3” or “if A, then B.” The tools we have now and the bright promise of rapidly evolving techniques in data science will not be maximised if not applied to real world problems and data. I would highly encourage anyone to get involved and get their hands dirty with existing projects—apart from the opportunity to build on technical skills, it teaches a great deal of practical lessons about communication, project and time management, and collaboration which are all highly useful in driving projects forward, growing in your practice, having fun, and hopefully, making a difference!"
  },
  {
    "objectID": "posts/2023-04-02-bridging-the-chasm/index.html#footnotes",
    "href": "posts/2023-04-02-bridging-the-chasm/index.html#footnotes",
    "title": "Bridging the chasm of expectations and reality with real-world projects",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nShala DR, Sheppard‐Law S. Measuring text similarity and its associated factors in electronic nursing progress notes: A retrospective review. Journal of Clinical Nursing. May 2022. https://doi.org/10.1111/jocn.16374↩︎\nShala DR, Sheppard-Law S. Need We Say More? Measuring Redundancy in Nursing Progress Notes. In Nurses and Midwives in the Digital Age 2021 (pp. 65-67). IOS Press. https://ebooks.iospress.nl/volumearticle/58617↩︎"
  },
  {
    "objectID": "posts/2023-11-30-advent-of-code/index.html",
    "href": "posts/2023-11-30-advent-of-code/index.html",
    "title": "Advent of Code",
    "section": "",
    "text": "seandeboo@gmail.com\n\n\n linkedin.com/in/sean-de-boo-a2551035"
  },
  {
    "objectID": "posts/2023-11-30-advent-of-code/index.html#what-is-it",
    "href": "posts/2023-11-30-advent-of-code/index.html#what-is-it",
    "title": "Advent of Code",
    "section": "What is it?",
    "text": "What is it?\nAdvent of Code (AOC) is an annual event in the coding community, signalling the arrival of the Christmas season with coding challenges that test your skills as a coder with a touch of humour thrown in. The AOC was created by Eric Wastl and consists of challenges released daily from December 1st to December 25th. These challenges cover topics such as algorithms, data structures, mathematics, and more, many of which you may encounter at a Data Scientist.\nThe tasks are designed to be approachable yet stimulating, making them suitable for coders of various skill levels. Early challenges can be as simple as adding groups of numbers together whilst later challenges often require algorithms where brute force techniques are not possible. Each person is also given a unique dataset to work with, so everyone’s solution is unique. Part 2 each day is often a twist in the problem that either can be fixed with a small change in code, or perhaps lead to an hour(s) of frustration."
  },
  {
    "objectID": "posts/2023-11-30-advent-of-code/index.html#why-participate",
    "href": "posts/2023-11-30-advent-of-code/index.html#why-participate",
    "title": "Advent of Code",
    "section": "Why Participate?",
    "text": "Why Participate?\nSkill Enhancement The challenges crafted to encourage problem-solving and critical thinking, helping enhance coding skills. Especially true for unstructured data. Often a key challenge each day is to convert the raw data into a workable format from which a solution can be found.\nFestive Spirit The challenges are infused with a holiday theme, adding a touch of humour to the coding experience.\nDebugging Practice Use of the smaller test data within the problem statement is a useful way to test code without having to analyse the whole data set. Breaking the problem into a smaller size and catching errors before running on the full dataset saves time and can be updated more quickly."
  },
  {
    "objectID": "posts/2023-11-30-advent-of-code/index.html#an-example-from-last-year",
    "href": "posts/2023-11-30-advent-of-code/index.html#an-example-from-last-year",
    "title": "Advent of Code",
    "section": "An example from last year",
    "text": "An example from last year\nLet’s take a look at a sample challenge from Day 2 of Advent of Code 2022. Here is a synopsis of the puzzle:\nA hypothetical game of Rock, Paper, Scissors is set up by the elves, with a unique scoring system. The winner of the whole tournament is the player with the highest score. Your total score is the sum of your scores for each round. The score for a single round is the score for the shape you selected (1 for Rock, 2 for Paper, and 3 for Scissors) plus the score for the outcome of the round (0 if you lost, 3 if the round was a draw, and 6 if you won). After a number of rounds, using a predetermined strategy, the final score needs to be calculated.\n\n\n\nIn Advent of Code 2022 coders solved puzzles to assist a camp of hapless, truculent elves. (Image generated with Stable Diffusion)\n\n\nEvery user is provided with their own input to the puzzle, a text file with 2,500 letter pairs. The first column is what your opponent plays: A for Rock, B for Paper, and C for Scissors. The second column is what you play in response: X for Rock, Y for Paper, and Z for Scissors.\nThe input dataset is a pair of columns representing your oponents moves and your moves. The first three rows might look as below.\n\n\n     [,1] [,2]\n[1,] \"A\"  \"Y\" \n[2,] \"B\"  \"X\" \n[3,] \"C\"  \"Z\" \n\n\nThis example would be scored as follows:\n\nIn the first game, your opponent chooses Rock (A) and you choose Paper (Y). This would be scored as a total of 8, 2 for using paper and 6 because you won.\nIn the second game, your opponent chooses Paper (B) and you choose Rock (X). This results in a loss for you and a total score of 1 (1 + 0).\nIn the third game, you and your opponent both choose Scissors, ending in a draw and a scored 6 (3+3).\n\nBased on the first three rows the final score would be 15 (8+1+6). The challenge is to write code to calculate your total score based on the 2,500 rows in your unique input file."
  },
  {
    "objectID": "posts/2023-11-30-advent-of-code/index.html#a-solution",
    "href": "posts/2023-11-30-advent-of-code/index.html#a-solution",
    "title": "Advent of Code",
    "section": "A solution",
    "text": "A solution\nTo solve this using Python we can set up a dictionary of moves and scores which consists of {key: value} pairs. For example ('A', 'Y'): 8 is the scenario where Rock (A) plays Paper (Y), so looking up the key (‘A’, ‘Y’) points to the score 8. By looping though the list of games and accessing the value at each key, the final score can be calculated.\nBelow is my complete solution for Part 1 of this challenge\n\n# Day 2 Advent of code\n\n#read in the puzzle input\nmain = [l.strip().split(' ') for l in open('input.txt')]\n\n#read in the demo input \ntest = [l.strip().split(' ') for l in open('test.txt')]\n\n#point to the test or full dataset \nuse = main\n\n# part 1 look up values for the moves, store in a dictionary\nmove = {('A', 'X'): 4, ('A', 'Y'): 8, ('A', 'Z'): 3,\n        ('B', 'X'): 1, ('B', 'Y'): 5, ('B', 'Z'): 9,\n        ('C', 'X'): 7, ('C', 'Y'): 2, ('C', 'Z'): 6}\n\n#play though the moves one by one, sum and then print final score\nt = 0\nfor elf, me in use:\n    t = t + move[(elf, me)]\nprint(t)"
  },
  {
    "objectID": "posts/2023-11-30-advent-of-code/index.html#steps-to-solve-the-problem",
    "href": "posts/2023-11-30-advent-of-code/index.html#steps-to-solve-the-problem",
    "title": "Advent of Code",
    "section": "Steps to Solve the Problem",
    "text": "Steps to Solve the Problem\nReading Input The code reads input from a file (input.txt in this example) to simulate real-world scenarios where input data is often provided externally.\n\n#read in the puzzle input\nmain = [l.strip().split(' ') for l in open('\\\\aoc\\\\input.txt')]\n\nThe Python functions strip() and split() are used to strip away white space and split the data into pairs of moves and store in a list.\nSetting up the dictionary This part of the code sets up the dictionary of {key:value} pairs for the moves and scores.\n\n# part 1 look up values for the moves, store in a dictionary\nmove = {('A', 'X'): 4, ('A', 'Y'): 8, ('A', 'Z'): 3,\n        ('B', 'X'): 1, ('B', 'Y'): 5, ('B', 'Z'): 9,\n        ('C', 'X'): 7, ('C', 'Y'): 2, ('C', 'Z'): 6}\n\nThere are only nine possible combinations so it is easy to work this out in advance.\nLooping through the input This is where you loop through each line of the input text file and use the dictionary to calculate the result of each round.\n\n#play though the moves one by one, sum and then print final score\nt = 0\nfor elf, me in use:\n    t = t + move[(elf, me)]\nprint(t)\n\nAn advantage of a for loop in python is that the method will iterate through an entire list without having to define the length beforehand."
  },
  {
    "objectID": "posts/2023-11-30-advent-of-code/index.html#final-thoughts",
    "href": "posts/2023-11-30-advent-of-code/index.html#final-thoughts",
    "title": "Advent of Code",
    "section": "Final thoughts",
    "text": "Final thoughts\nThe Advent of Code is not just a coding challenge, it’s a fun way to test your skills and often be amazed that each day competitive coders from around the solve the problems in a matter of minutes. Whether you’re just starting to code, or experienced, participating is a great way to embrace the festive spirit while practicing your skills."
  },
  {
    "objectID": "posts/2023-11-30-advent-of-code/index.html#taking-part",
    "href": "posts/2023-11-30-advent-of-code/index.html#taking-part",
    "title": "Advent of Code",
    "section": "Taking part",
    "text": "Taking part\nTo take part in Advent of Code 2023 the first step is to sign up at adventofcode.com/2023/auth/login. To join the CBDRH leaderboard go to adventofcode.com/2023/leaderboard/private and enter the code 2314975-9001d5ff. Happy coding!"
  },
  {
    "objectID": "tutorial.html",
    "href": "tutorial.html",
    "title": "Wondering if a career in Health Data Science is for you?",
    "section": "",
    "text": "A guided tutorial in Health Data Science\nTry working through the guided tutorial below to get a feel for what it is like to undertake a health data analysis. You will work through six important steps to answer real health data science questions. This is an introductory-level tutorial so don’t worry if you are new to statistics or coding.\nNote This section is designed as an interactive tutorial, so get ready to be presented with questions and exercises! The reading time to complete the six steps is around 20-30 minutes in total and this should give you a gentle introduction to the types of content covered in the Masters of Science in Health Data Science. It is possible to complete this tutorial on a smartphone screen, but may be easier to view on a larger screen\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactors which influence birthweight\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 1. The research question\n\n\nIn any health data science analysis, the first step is to undersand the research question\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 2. Curating the data\n\n\nAs a data scientist you will learn to document and manage the data you analyse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 3. Exploring the data\n\n\nExploratory data analysis helps you to understand the data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 4. Descriptive Modelling\n\n\nUse statistical modelling to gain health insights\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 5. Predictive modelling\n\n\nCan you use machine learning to predict future health outcomes?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 6. Conclusions\n\n\nWhat have we learned?\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "courses.html",
    "href": "courses.html",
    "title": "Courses",
    "section": "",
    "text": "Analysis Software\n\n\nNone\n\n\nPrerequisites\n\n\nUndergraduate: Enrolment in 3831 Science (Medicine) HonoursPostgraduate: None\n\n\nHandbook\n\n\nhandbook.unsw.edu.au/postgraduate/courses/2023/HDAT9100\n\n\nTimetable\n\n\ntimetable.unsw.edu.au/2023/HDAT9100.html\n\nThe Context of Health Data Science provides an introduction to how data are generated and used in a contemporary health system. We look at how health outcomes can be measured and reported in various forms of health data, and how these health data can reveal inequalities in health. The course describes the major sources of health data, including those relating to primary care, hospital stays and prescription medicines, and how this (and other) information can be used by the health data scientist to create evidence for policy and research.\nActivities are structured to foster a scientific, questioning attitude in the student. Students are encouraged to think critically about how health data are recorded, what this reveals about the underlying health delivery systems, and be creative in their use of health data sources to create or critically appraise evidence."
  },
  {
    "objectID": "courses.html#hdat9100",
    "href": "courses.html#hdat9100",
    "title": "Courses",
    "section": "",
    "text": "Analysis Software\n\n\nNone\n\n\nPrerequisites\n\n\nUndergraduate: Enrolment in 3831 Science (Medicine) HonoursPostgraduate: None\n\n\nHandbook\n\n\nhandbook.unsw.edu.au/postgraduate/courses/2023/HDAT9100\n\n\nTimetable\n\n\ntimetable.unsw.edu.au/2023/HDAT9100.html\n\nThe Context of Health Data Science provides an introduction to how data are generated and used in a contemporary health system. We look at how health outcomes can be measured and reported in various forms of health data, and how these health data can reveal inequalities in health. The course describes the major sources of health data, including those relating to primary care, hospital stays and prescription medicines, and how this (and other) information can be used by the health data scientist to create evidence for policy and research.\nActivities are structured to foster a scientific, questioning attitude in the student. Students are encouraged to think critically about how health data are recorded, what this reveals about the underlying health delivery systems, and be creative in their use of health data sources to create or critically appraise evidence."
  },
  {
    "objectID": "courses.html#hdat9200",
    "href": "courses.html#hdat9200",
    "title": "Courses",
    "section": "HDAT9200 Statistical Foundations for Health Data Science",
    "text": "HDAT9200 Statistical Foundations for Health Data Science\n\nAnalysis Software\n\n\nR/RStudio\n\n\nPrerequisites\n\n\nUndergraduate: Enrolment in 3831 Science (Medicine) HonoursPostgraduate: None\n\n\nHandbook\n\n\nhandbook.unsw.edu.au/postgraduate/courses/2023/HDAT9200\n\n\nTimetable\n\n\ntimetable.unsw.edu.au/2023/HDAT9200.html\n\nHealth data is often complex and noisy. Obtaining actionable insights (or revealing the hidden signals) from such data requires the utilisation of probabilistic concepts. Thus a solid understanding of the principles of statistics is intrinsic to Health Data Science. The aim of this first course in probability theory is to introduce the foundations required to understand such phenomena.\nThe course design is highly innovative and novel. Statistical computing is used to gain a sound understanding of statistical theories and concepts. Specifically, this course draws on the practical application of Monte Carlo algorithms, which are a very effective method of statistical computing. Once this illustrative approach has (a posteriori) demonstrated a theory, it will then be stated formally.\nThe core content will be delivered through a flipped approach utilising audio-visual excerpts on the Moodle TELT platform, supported by presentations from Centre for Big Data Research in Health (CBDRH) experts. Statistical computing will be used as the process that drives the content. Peer instruction via discussion during face-to-face sessions will offer support in the form of collaborative learning. Active participation will be encouraged throughout, along with a reflective outlook."
  },
  {
    "objectID": "courses.html#hdat9300",
    "href": "courses.html#hdat9300",
    "title": "Courses",
    "section": "HDAT9300 Computing for Health Data Science",
    "text": "HDAT9300 Computing for Health Data Science\n\nAnalysis Software\n\n\nPython\n\n\nPrerequisites\n\n\nUndergraduate: Enrolment in 3831 Science (Medicine) HonoursPostgraduate: None\n\n\nHandbook\n\n\nhandbook.unsw.edu.au/postgraduate/courses/2023/HDAT9300\n\n\nTimetable\n\n\ntimetable.unsw.edu.au/2023/HDAT9300.html\n\nComputing now pervades nearly every aspect of modern life, including health care delivery and health services management. The objective of this course is to develop ‘computational thinking’ in health data science students, by providing you with a thorough and principled introduction to computer programming, algorithms, data structures and software engineering best practices. The ability to write clear, efficient and correct computer code is at the core of most data science practice and is a foundation skill set.\nIn this course, you will learn to program in the Python language through tackling health-related problems. Topics include data types, functions, data processing, simulation, software development and program testing and debugging. Theoretical principles are reinforced with extensive ‘hands-on’ coding in Python, including the NumPy and Pandas packages.\nThe course is accessed via www.openlearning.com. Core material will be delivered as short lectures and readings supported by interactive coding activities. Practical exercises will utilise Spyder/Jupyter Notebook documents."
  },
  {
    "objectID": "courses.html#hdat9400",
    "href": "courses.html#hdat9400",
    "title": "Courses",
    "section": "HDAT9400 Data Management & Curation",
    "text": "HDAT9400 Data Management & Curation\n\nAnalysis Software\n\n\nSAS\n\n\nPrerequisites\n\n\nUndergraduate: Enrolment in 3831 Science (Medicine) HonoursPostgraduate: None\n\n\nHandbook\n\n\nhandbook.unsw.edu.au/postgraduate/courses/2023/HDAT9400\n\n\nTimetable\n\n\ntimetable.unsw.edu.au/2023/HDAT9400.html\n\nThis course is designed to equip students with the skills required to collect or obtain data, design data management strategies aligned with best practice, and appreciate the day to day practicalities of data curation for sound data management. Students will develop data wrangling skills required to assemble data suitable for analysis and research purposes, including data from linkage projects. Data wrangling skills will focus on the key areas of data security, data exploration, documentation of data (for example data dictionaries) and data management, with the ultimate aim of creating analysis-ready datasets and ensuring reproducible results."
  },
  {
    "objectID": "courses.html#hdat9500",
    "href": "courses.html#hdat9500",
    "title": "Courses",
    "section": "HDAT9500 Machine Learning I",
    "text": "HDAT9500 Machine Learning I\n\nAnalysis Software\n\n\nPython\n\n\nPrerequisites\n\n\nUndergraduate: Enrolment in 3831 Science (Medicine) HonoursPostgraduate: HDAT9200 and HDAT9300 (or COMP9021)\n\n\nHandbook\n\n\nhandbook.unsw.edu.au/postgraduate/courses/2023/HDAT9500\n\n\nTimetable\n\n\ntimetable.unsw.edu.au/2023/HDAT9500.html\n\nHealthcare organisations have a vast amount of data: electronic medical records, claims, registries, medical images, and other types of digital health data. Machine learning techniques learn from previous experience in order to discover patterns and relationships in data, and have been found to perform extremely well in large datasets.\nThis course provides an introduction to machine learning techniques through a series of health applications.\nAlgorithms for supervised and unsupervised learning are covered, including linear regression and classification, tree-based methods, clustering, dimensionality reduction and neural networks.\nStudents will learn about the underlying supporting theory of these techniques, as well as gain the applied practical skills required to effectively apply these techniques to new health data problems."
  },
  {
    "objectID": "courses.html#hdat9510",
    "href": "courses.html#hdat9510",
    "title": "Courses",
    "section": "HDAT9510 Machine Learning II",
    "text": "HDAT9510 Machine Learning II\n\nAnalysis Software\n\n\nPython\n\n\nPrerequisites\n\n\nPostgraduate: HDAT9500\n\n\nHandbook\n\n\nhandbook.unsw.edu.au/postgraduate/courses/2023/HDAT9510\n\n\nTimetable\n\n\ntimetable.unsw.edu.au/2023/HDAT9510.html\n\nThis will be an advanced course on machine learning for health data scientists.\nThis course will cover advanced contemporary machine learning algorithms and methods.\nAlong with the theory, this course will cover a range of health applications for real-world translation and deployment.\nThis course is designed to build upon the content of HDAT9500 by further progressing the knowledge in the theory, technologies and solutions currently needed by Health Data Scientists working in the area of applied machine learning."
  },
  {
    "objectID": "courses.html#hdat9600",
    "href": "courses.html#hdat9600",
    "title": "Courses",
    "section": "HDAT9600 Statistical Modelling I",
    "text": "HDAT9600 Statistical Modelling I\n\nAnalysis Software\n\n\nR/RStudio\n\n\nPrerequisites\n\n\nPostgraduate: HDAT9200\n\n\nHandbook\n\n\nhandbook.unsw.edu.au/postgraduate/courses/2023/HDAT9600\n\n\nTimetable\n\n\ntimetable.unsw.edu.au/2023/HDAT9600.html\n\nThis course provides a sound grounding in the theory and practice of fitting statistical regression models, with particular focus on the flexibility of generalised linear models (GLMs). Starting with linear regression, a major theme of the course is best practice in model fitting, including thorough exploratory data analysis, model assumption checking, data preparation and transformation, including the use of imputation, and careful attention to model adequacy and diagnostics. Emphasis is given to content-aware, purposive model building and the use of Directed Acyclic Graphs (DAGs) of causal relations to inform model parameter selection. Non-linear, logistic, binomial and Poisson models for count data are also covered. Effect modifications (interactions) and their meaning in a health context are explored. The presentation and visualisation of statistical models is considered, with emphasis on the explanatory insights that can be gained from well-constructed models. The final part of the course covers basic time-series models, survival analysis and other time-to-event models."
  },
  {
    "objectID": "courses.html#hdat9700",
    "href": "courses.html#hdat9700",
    "title": "Courses",
    "section": "HDAT9700 Statistical Modelling II",
    "text": "HDAT9700 Statistical Modelling II\n\nAnalysis Software\n\n\nR/RStudio\n\n\nPrerequisites\n\n\nPostgraduate: HDAT9200 and HDAT9600\n\n\nHandbook\n\n\nhandbook.unsw.edu.au/postgraduate/courses/2023/HDAT9700\n\n\nTimetable\n\n\ntimetable.unsw.edu.au/2023/HDAT9700.html\n\nSophisticated modelling techniques are essential for the analysis of real-world health data. Building on Health Data Analytics: Statistical Modelling I (HDAT9600), this course expands the statistical toolkit and broadens students’ understanding of relevant statistical approaches for the analysis of realistically complex data structures and research questions. The course is aimed at those currently working or planning on working in health or a health-related field, and who are interested in applying advanced statistical methods to analyse complex data.\nTopics covered in this course include multilevel models for hierarchical data; analysis of time series and longitudinal data; quasi-experimental approaches for drawing causal inferences from observational data; multiple imputation for missing values; and simulation approaches for study planning and model evaluation.\nContent is delivered through a combination of online readings, expert guest lectures and practical hands-on tutorials. Statistical concepts are illustrated with a variety of health examples, and students will learn how to implement methods using leading statistical software. Lectures are followed by weekly exercises, which reinforce the learning and programming skills covered in the face-to-face tutorials."
  },
  {
    "objectID": "courses.html#hdat9800",
    "href": "courses.html#hdat9800",
    "title": "Courses",
    "section": "HDAT9800 Visualisation & Communication",
    "text": "HDAT9800 Visualisation & Communication\n\nAnalysis Software\n\n\nR/RStudio\n\n\nPrerequisites\n\n\nPostgraduate: None\n\n\nHandbook\n\n\nhandbook.unsw.edu.au/postgraduate/courses/2023/HDAT9800\n\n\nTimetable\n\n\ntimetable.unsw.edu.au/2023/HDAT9800.html\n\nHealth Data Scientists need to present information to audiences across a range of backgrounds and spanning a spectrum from naïve or non-practitioners of a discipline to highly informed and expert audiences. Effective communication across different media types is essential. Appropriate data visualisation techniques can greatly enhance communication and increase the effectiveness of communication. Increasingly the scientific community has become aware of problems regarding lack of transparency and reproducibility.\nThis course takes a toolbox approach to creating appropriate, reproducible and transparent analyses and visualisations. In the context of R, it presents useful best-practice data science analysis and visualisation techniques with a focus on different types of data visualisations.\nA basic understanding of how people process information can ensure communication remains effective to an audience with a disability."
  },
  {
    "objectID": "courses.html#hdat9900",
    "href": "courses.html#hdat9900",
    "title": "Courses",
    "section": "HDAT9900/9901/9902 Dissertation",
    "text": "HDAT9900/9901/9902 Dissertation\n\nAnalysis Software\n\n\nProject dependent\n\n\nPrerequisites\n\n\nPostgraduate: HDAT9100, HDAT9400, HDAT9500, HDAT9700 and HDAT9800\n\n\nHandbook\n\n\nhandbook.unsw.edu.au/postgraduate/courses/2023/HDAT9900\n\n\nTimetable\n\n\ntimetable.unsw.edu.au/2023/HDAT9900.html\n\nThe Dissertation is a total of 24 UoC. A combination of HDAT9900, HDAT9901, and HDAT9902 totalling 24 UoC must be completed over two, three or four terms.\nThe course consists of independent research with an academic supervisor. The learning from the Graduate Diploma scaffolds to this ‘real-world’ project. In addition to developing sound project management skills, this course facilitates the bigger picture - the Health Data Science pipeline is experienced from start to finish.\nSupport is given via weekly supervisory meetings, supplemented with additional workshops dependent on specific project requirements. An additional early checkpoint involves the development and submission of study protocol and literature review. The final outputs will mirror those of a real world academic setting. Specifically the production of a manuscript to the specifications of a peer reviewed journal relevant to the project and of publishable standard. The project is also to be disseminated orally via a 15 minute presentation (including 5 minutes of questions and answers).\nStudents are required to complete Graduate Diploma to a satisfactory standing to be admitted onto this course. The choice of project could either be selected from an offered list of projects or developed from students proposals, dependent on the availability of a suitable supervisor and agreement on project topic.\nStudents are required to complete 24uoc in Dissertation courses over a number of terms. This can be completed on a full-time or part-time basis."
  },
  {
    "objectID": "courses.html#hdat9910",
    "href": "courses.html#hdat9910",
    "title": "Courses",
    "section": "HDAT9910 Capstone",
    "text": "HDAT9910 Capstone\n\nAnalysis Software\n\n\nR/Rstudio and/or Python\n\n\nPrerequisites\n\n\nPostgraduate: HDAT9100, HDAT9400, HDAT9500, HDAT9700 and HDAT9800\n\n\nHandbook\n\n\nhandbook.unsw.edu.au/postgraduate/courses/2023/HDAT9910\n\n\nTimetable\n\n\ntimetable.unsw.edu.au/2023/HDAT9910.html\n\nThe learning from the Graduate Diploma (5372) scaffolds to this six unit of credit ‘desk-based’ research, capstone project. The overarching aim is to facilitate the bigger picture of Health Data Science (HDS); the student experiences the HDS pipeline from start-to-end. Thus, the student is presented with the opportunity to bring all the content of the Graduate Diploma together, realising the relative ordering and merits of each stage. This capstone has the advantage of allowing a further 18 units of credit of broadening electives to be undertaken.\nThe capstone project involves completing extensive, desk-based, independent research tasks, requiring the use of the R and/or Python programming languages. An entire HDS project has been constructed and sliced into the respective stages of the HDS pipeline. At each stage, the student has the option of completing minor or major tasks to progress to the next stage. For example, at the ‘Curation’ stage, a minor task might be a short-written report (circa 1,000 words) identifying the issues to be addressed. A major task would involve preparation of a data management plan (DMP; circa 3,000 words). Each task will be assigned a point score based on its complexity, proportional to the expected (notional) time required to complete the task. To complete the course, will require successful completion of three minor and two major tasks.\nStudents are required to complete Graduate Diploma in Health Data Science (5372) to a satisfactory standing to be admitted onto this course."
  },
  {
    "objectID": "courses.html#hdat9000",
    "href": "courses.html#hdat9000",
    "title": "Courses",
    "section": "HDAT9000 Clinical Artificial Intelligence",
    "text": "HDAT9000 Clinical Artificial Intelligence\n\nAnalysis Software\n\n\nExamples can be run in Python or Excel\n\n\nPrerequisites\n\n\nUndergraduate: Enrolment in 3831 Science (Medicine) Honours\n\n\nHandbook\n\n\nhandbook.unsw.edu.au/postgraduate/courses/2023/HDAT9000\n\n\nTimetable\n\n\ntimetable.unsw.edu.au/2023/HDAT9000.html\n\nThe course will start by explaining the fundamental concepts of AI systems and what they can and cannot do. This will be followed by an examination of the idiosyncrasies of AI for healthcare practice covering electronic medical records data (including images, clinical notes, pathology and patient reported outcomes), clinical settings and workflows, as well as the ethical, social, and legal issues posed by the use of AI technologies in clinical practice. Students will generate and discuss a survey of major AI solutions in healthcare practice. The course will then provide students with best-practice guidance, methods and tools on when to use AI to improve patient care, how to deploy an AI project pipeline, how to critically assess the performance and impact of the proposed AI solution and what pitfalls to avoid."
  },
  {
    "objectID": "webexercises.html",
    "href": "webexercises.html",
    "title": "Webexercises",
    "section": "",
    "text": "This is a Web Exercise template created by the psychology teaching team at the University of Glasgow, based on ideas from Software Carpentry. This template shows how instructors can easily create interactive web documents that students can use in self-guided learning.\nThe {webexercises} package provides a number of functions that you use in inline R code or through code chunk options to create HTML widgets (text boxes, pull down menus, buttons that reveal hidden content). Examples are given below. Render this file to HTML to see how it works.\nNOTE: To use the widgets in the compiled HTML file, you need to have a JavaScript-enabled browser."
  },
  {
    "objectID": "webexercises.html#example-questions",
    "href": "webexercises.html#example-questions",
    "title": "Webexercises",
    "section": "Example Questions",
    "text": "Example Questions\n\nFill-In-The-Blanks (fitb())\nCreate fill-in-the-blank questions using fitb(), providing the answer as the first argument.\n\n2 + 2 is \n\nYou can also create these questions dynamically, using variables from your R session.\n\nThe square root of 9 is: \n\nThe blanks are case-sensitive; if you don’t care about case, use the argument ignore_case = TRUE.\n\nWhat is the letter after D? \n\nIf you want to ignore differences in whitespace use, use the argument ignore_ws = TRUE (which is the default) and include spaces in your answer anywhere they could be acceptable.\n\nHow do you load the tidyverse package? \n\nYou can set more than one possible correct answer by setting the answers as a vector.\n\nType a vowel: \n\nYou can use regular expressions to test answers against more complex rules.\n\nType any 3 letters: \n\n\n\nMultiple Choice (mcq())\n\n“Never gonna give you up, never gonna: let you goturn you downrun awaylet you down”\n“I bless the rainsguess it rainssense the rain down in Africa” -Toto\n\n\n\nTrue or False (torf())\n\nTrue or False? You can permute values in a vector using sample(). TRUEFALSE\n\n\n\nLonger MCQs (longmcq())\nWhen your answers are very long, sometimes a drop-down select box gets formatted oddly. You can use longmcq() to deal with this. Since the answers are long, It’s probably best to set up the options inside an R chunk with echo=FALSE.\nWhat is a p-value?\n\n the probability that the null hypothesis is true the probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is true the probability of making an error in your conclusion\n\nWhat is true about a 95% confidence interval of the mean?\n\n there is a 95% probability that the true mean lies within this range 95% of the data fall within this range if you repeated the process many times, 95% of intervals calculated in this way contain the true mean"
  },
  {
    "objectID": "webexercises.html#checked-sections",
    "href": "webexercises.html#checked-sections",
    "title": "Webexercises",
    "section": "Checked sections",
    "text": "Checked sections\nCreate sections with the class webex-check to add a button that hides feedback until it is pressed. Add the class webex-box to draw a box around the section (or use your own styles).\n\nI am going to learn a lot: TRUEFALSE\nWhat is a p-value?\n\n the probability that the null hypothesis is true the probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is true the probability of making an error in your conclusion"
  },
  {
    "objectID": "webexercises.html#hidden-solutions-and-hints",
    "href": "webexercises.html#hidden-solutions-and-hints",
    "title": "Webexercises",
    "section": "Hidden solutions and hints",
    "text": "Hidden solutions and hints\nYou can fence off a solution area that will be hidden behind a button using hide() before the solution and unhide() after, each as inline R code. Pass the text you want to appear on the button to the hide() function.\nIf the solution is a code chunk, instead of using hide() and unhide(), simply set the webex.hide chunk option to TRUE, or set it to the string you wish to display on the button.\nRecreate the scatterplot below, using the built-in cars dataset.\n\n\n\n\n\n\n\nI need a hint\n\nSee the documentation for plot() (?plot)\n\n\n\n\n\nClick here to see the solution\n\nplot(cars$speed, cars$dist)"
  },
  {
    "objectID": "posts/2023-02-06-balancing-life-and-study/index.html",
    "href": "posts/2023-02-06-balancing-life-and-study/index.html",
    "title": "Balancing life and study",
    "section": "",
    "text": "jmeyer2482@gmail.com"
  },
  {
    "objectID": "posts/2023-02-06-balancing-life-and-study/index.html#how-it-started",
    "href": "posts/2023-02-06-balancing-life-and-study/index.html#how-it-started",
    "title": "Balancing life and study",
    "section": "How it started",
    "text": "How it started\nI embarked on the journey of completing my Masters in Health Data Science in late 2018. I had been mulling over the idea of post grad study for a while at that point but had not seen anything that really took my interest. I think I might have actually seen an add for this degree on Facebook and decided to take closer look. The appeal for me was the mix of data science with a clinical skew that would have application in my current work.\nI put in an application and was successful to start in the first term of 2019. At the time I was a full fee paying student (via HECS). I decided I would just do one subject per term to make sure I could manage the workload without impacting the rest of family too much."
  },
  {
    "objectID": "posts/2023-02-06-balancing-life-and-study/index.html#managing-obstacles",
    "href": "posts/2023-02-06-balancing-life-and-study/index.html#managing-obstacles",
    "title": "Balancing life and study",
    "section": "Managing Obstacles",
    "text": "Managing Obstacles\n\nTime\nI was fortunate enough that I was able to negotiate flexible working hours which allowed me to work a full-time load over 4 days which left me the Friday every week to study. Thanks to the technological aspirations of the course, pretty much all the content was available online and there was only a few subject I missed the tutes for which I made up for by engaging online.\nWeek to week I would work through what I could during the evenings when I had free time and then finish things off on the Friday. Some weeks I would have the Friday free to attend to other duties because I already had experience in the course content for that week. Then I would generally spend extra time on the weekends to get on top of assignment deadlines.\nAt the start of each term I would map out the course deadlines on my calendar. I would make a plan for spending extra time on the assignments (I always used it). The week to week work was generally okay but if it was heavy and you got an assignment on top, it made it more difficult to keep on top. I always prioritised work that would give marks.\nI will say that my wife was amazing through the whole degree even though she definitely got frustrated at times. It can be difficult to balance the time commitments of study, work and family life. I would not recommend undertaking them without the full support of your significant other (if that is your situation).\n\n\n\nJason pictured with his family (author supplied)\n\n\n\n\nFamily\nIn 2020, we had a second child join us. We called him our COVID baby. This period was initially very agreeable to studying as pretty well everyone had to stay at home. I was considered frontline staff so still had to go to work but my wife was on maternity leave. All the course content was already online. It was just a case of continuing the practices I had started in 2019.\nIn 2021, restrictions were lifted and things started to open up more. My wife went back to work three days a week. Both kids were in day care four days a week. We still managed to work things so that both my wife and I had a day at home each without the kids. For me it was largely to study, for my wife it was to get a break and catch up on things.\n\n\nExpenses\nThe cost of a Masters can be prohibitive. I had a requirement through my employer to be working towards a higher degree so there was incentive to maintain studies based on that. However, after paying $3,500+ per subject we were beginning to feel the pinch. There were no Commonwealth Supported Places (CSP) when I had originally applied however, I had been keeping in touch with the Program Director (Sabita then Andrew) to see if there were any opportunities. Towards the end of 2020 the federal government had announced additional funding for STEM placements but I found out that they were only going to apply to new applicants. So at the end of 2020 I withdrew from my Masters and reapplied to commence in Term 1 2021. My gamble for securing a CSP paid off. My course fees went from around $4,000 to around $900!"
  },
  {
    "objectID": "posts/2023-02-06-balancing-life-and-study/index.html#lessons",
    "href": "posts/2023-02-06-balancing-life-and-study/index.html#lessons",
    "title": "Balancing life and study",
    "section": "Lessons",
    "text": "Lessons\nAt the end of 2022, I completed my dissertation with a high distinction and had a weighted average mark of 90% for my entire Masters degree. To say I was chuffed would be an understatement.\nWriting out what I’ve been through for this blog makes it sound like it was actually a pretty straightforward thing to do. I haven’t gone into the depths of how we also moved house twice, sold a house, bought a house, changed the kids to different day care centres, plus managing all the routine day-to-day life things that get thrown at you. Not to mention work deadlines that come up as well! These are all the small things that suck up your time, often at critical moments because they are largely unplanned.\nWhat did I do to ensure that I was successful?\n\nMade sure my wife was on board\nGave myself a solid chunk of flexible time\nAttempted to use up other spare time before I got to my allocated time (if things were under control when I got to my allocated time then it could be used as free time or time for doing other things)\nNegotiated additional time requirements with my wife when needed (usually for assignments)\nPrioritised work that gave marks\n\nOne other thing that I think is important in a situation like this. If you aren’t in a position where you are relying on others to accomplish things then it doesn’t matter as much but I very much was. It was important to me that the time I was spending on study was not wasted. I felt a strong obligation to succeed in all the courses because I did not want the time I was taking away to be wasted."
  },
  {
    "objectID": "posts/2023-06-26-medical-students-living-the-clinical-ai-stream/index.html",
    "href": "posts/2023-06-26-medical-students-living-the-clinical-ai-stream/index.html",
    "title": "Medical students living the Clinical AI dream",
    "section": "",
    "text": "l.dettmann_hughes@student.unsw.edu.au\n\n\n linkedin.com/in/liam-dettmann-hughes-456bba258\n\n\n\n\n elisabethabh@gmail.com\n\n\n\n\n\n\nLiam and Elisabeth are fourth-year UNSW medical students who are currently undertaking coursework-intensive honours in the Clinical AI program. Liam is researching the relationship between computer mouse activity and mental health status using machine learning. Elisabeth is working with the Centre for Big Data Research in Health to better understand barriers and facilitators of the implementation of AI systems in general practice.\n\nWhy Choose Clinical AI?\nEarly last year we were presented with a unique opportunity for our honours year—a coursework-intensive honours stream focused on clinical AI. As we selected the stream during its inaugural year, we weren’t sure what to expect, but the prospect of becoming data science-literate medical students was convincing enough! Many of our peers have long held a passion for data science or an unexplored ambition to establish a healthcare AI startup and similarly jumped at this exciting opportunity.\nArtificial intelligence has been the headline news story of 2023. AI discovered a new antibiotic, Halicin, in 2019, and is already being used in imaging analysis and clinical decision-making. AI offers limitless opportunities to enhance patient outcomes by facilitating a more personalised approach to medical care, decreasing human errors, improving the accuracy and speed of diagnosis, reducing healthcare costs and increasing doctor-patient engagement. As expected with any major technological shift, this excitement has been accompanied with growing uncertainty surrounding what the role of a doctor will look like in the future. Ultimately, technology in medicine is here to stay, and while change in medical practice is inevitable, we think that the impending digital revolution in healthcare offers immense opportunities to healthcare workers and is a cause for excitement rather than pessimism. Doctors will be integral in identifying areas in the healthcare system that can be optimised by technology, and applying and interpreting new technology will become central to the role of medical practitioners.\nWe see the clinical AI program as an invaluable introduction to this unfolding healthcare transformation and as a fantastic opportunity to understand how medicine and AI will intersect. We aim to not only leverage the power of data science to enhance patient care, but also to contribute to the advancement of medical research and healthcare systems as a whole. This immersive experience allows us to gain a deep understanding of the applications and limitations of AI in the clinical setting, and how it can be harnessed to transform healthcare delivery. The coursework offers us a taste of the necessary skills needed to navigate the emerging landscape of AI in healthcare.\n\n\n\nStructure of the Clinical AI program and what we have learned\nAlongside our independent research projects, the Clinical AI coursework consists of two courses in each of Terms 1 and 2, taken from the Masters of Health Data Science program. In Term 1, there were four contact hours per week, with a large part of the learning conducted through self-directed modules and activities.\nIn HDAT9100, we explored the intricacies of data creation in the health system and its utilisation in analysis and research. We learned to think critically about the limitations and biases associated with different mediums of health data and explored creative methods to overcome these challenges. We also looked at how health outcomes could be measured and analysed to identify areas of inequality and create evidence for policy. Understanding the nuances of healthcare data helped us to better understand the structure of the public and private health systems and complemented our clinical experience.\nHDAT9300 provided our first formal education in computer programming in the Python language, which was particularly exciting. The course emphasised the importance of code that not only functions correctly, but is also written efficiently and clearly. The assignments in this course were especially engaging as they were themed around health-related problems, such as calculating kidney function, evaluating DNA sequences and analysing patient datasets. This highlighted the broad applications of software in medicine and prompted us to consider the role technology can play in creating scalable healthcare solutions. The course provided a strong introduction to the fundamentals of programming for us to build on in further courses and in our research.\nWith these strong foundations, we look forward to taking on AI itself in Term 2 and applying this knowledge to our research. HDAT9500 will introduce us to machine learning and data mining, while HDAT9000 will explore the opportunities and boundaries associated with applying AI to healthcare, as well as the complicated ethical, social and legal issues that arise in this space.\n\n\nWhat We Have Enjoyed About Clinical AI\nOne of the most rewarding aspects of the Clinical AI program has been the opportunity to expand our problem-solving abilities through coding. The assignments and projects have encouraged us to think analytically and creatively, applying our programming knowledge to health-related problems. This practical approach has sparked our curiosity about the broad applications of software in medicine and equipped us with the fundamental technical abilities necessary to tackle real-world healthcare challenges.\nThe flexibility of the program has also stood out. While there are structured contact hours every week, a significant portion of the learning is independent study that can be completed on your own time. This flexibility has provided us with a lot of freedom in choosing our research project and allowed us to explore topics of personal interest within the realm of clinical AI.\nCollaboration has been a central part of the clinical AI journey and has greatly enhanced our experience. The coursework fosters a supportive learning environment through team-based projects and group discussions. This reflects the reality of the healthcare setting, where teamwork is essential for achieving stronger outcomes.\n\n\nChallenges\nOne of the main challenges we have encountered during the Clinical AI program is finding a balance between our research projects, which have longer-term deadlines, with the more immediate demands of the coursework. Weekly assignments alleviate the stress of end-of-term exams but require a consistent and organised approach to coursework that must be maintained.\nTaking on the challenge of the coursework-intensive Clinical AI honours program has been well worth it. It’s been satisfying to see our knowledge and skills grow substantially in just one term and we are looking forward to what this new term has to offer as we continue to learn how to navigate the fascinating intersection between medicine and technology, which will only continue to converge in the future."
  },
  {
    "objectID": "posts/2023-03-01-studying-hds-as-a-junior-doctor/index.html",
    "href": "posts/2023-03-01-studying-hds-as-a-junior-doctor/index.html",
    "title": "Studying Health Data Science as a junior doctor",
    "section": "",
    "text": "roper.lucinda@gmail.com"
  },
  {
    "objectID": "posts/2023-03-01-studying-hds-as-a-junior-doctor/index.html#combining-work-and-study-early-in-the-degree",
    "href": "posts/2023-03-01-studying-hds-as-a-junior-doctor/index.html#combining-work-and-study-early-in-the-degree",
    "title": "Studying Health Data Science as a junior doctor",
    "section": "Combining work and study early in the degree",
    "text": "Combining work and study early in the degree\nI commenced the HDS Masters in 2019, while working as a junior doctor. Prior to this, I had completed an undergraduate research year with the Center for Big Data Research in Health as part of my medical degree, which I really enjoyed and I was interested in maintaining options for non-clinical work. The main advice I have for any junior doctors doing the course is that ward work is unpredictable, and a work-study schedule that looks reasonable on paper can be easily thrown off by unrostered overtime! I found it much easier to manage the course on shiftwork-based terms. My experience was that I could only ever manage one subject at a time, except for one term which was 4 days on, 4 off, 4 nights, 4 off, when I did two subjects."
  },
  {
    "objectID": "posts/2023-03-01-studying-hds-as-a-junior-doctor/index.html#dissertation-research-project-experience-being-integrated-into-a-research-organization-and-working-across-institutions",
    "href": "posts/2023-03-01-studying-hds-as-a-junior-doctor/index.html#dissertation-research-project-experience-being-integrated-into-a-research-organization-and-working-across-institutions",
    "title": "Studying Health Data Science as a junior doctor",
    "section": "Dissertation research project experience: being integrated into a research organization and working across institutions",
    "text": "Dissertation research project experience: being integrated into a research organization and working across institutions\nI really wanted the opportunity to fully focus on my dissertation research project, so decided to take six months off work to do this. I also hoped to remain in Darwin, where I was living and working. I approached the Menzies School of Health Research in Darwin, and was introduced to Professor Steven Guthridge, who was open to formulating the project based on their current research areas that were relevant to the NT, and supervising my research project, along with co-supervision from a UNSW academic. I really loved the Machine Learning chapter of the course and so I approached Dr Oscar Perez-Concha, who agreed to co-supervise my project, which was fantastic.\n\n\n\nLucinda pictured presenting to the judges at Royal Darwin Hospital in late 2021 (author supplied)\n\n\nWorking at the Menzies School of Health Research, specifically within the Child and Youth Development Research Partnership (CYDRP) was a highlight of my experience. The team at Menzies were very generous in integrating me into their workplace and I felt like a valued member and contributor to their team. CYDRP also have an amazing resource for retrospective analysis: a population-level linked database spanning 14 different datasets.\nOnce I had completed the research project, I was fortunate to receive a doctors in training research award for a presentation on the project.\n\n\n\n\nLucinda receiving a Doctors in Training research award (author supplied)"
  },
  {
    "objectID": "posts/2023-03-01-studying-hds-as-a-junior-doctor/index.html#lessons-learned",
    "href": "posts/2023-03-01-studying-hds-as-a-junior-doctor/index.html#lessons-learned",
    "title": "Studying Health Data Science as a junior doctor",
    "section": "Lessons learned",
    "text": "Lessons learned\nBecause of the opportunity for uninterrupted work, I delved deeply into the area of dimensionality reduction and clustering techniques using unsupervised machine learning. I had intended to have the project completed, and a manuscript submitted by the end of the six-month period. I found it hard to ‘draw the line’ and possibly delved too deeply into the subject matter, and instead had just completed a first draft at the end of the six-month period. Based on the amount of work done, there was possibly sufficient material for a second paper comparing clustering methodologies, however to make this paper relevant and concise, we elected to use 2 rather than all 6 of the various models that we had made. The main lesson for me was to set realistic expectations about what is achievable in a limited time frame, especially when you want to develop a deep understanding of new and complex subject matter. Perhaps this is an unavoidable trap for a junior researcher.\nWe submitted a manuscript to PLoS One in February 2022, a couple of months after completing the MSc Program in December 2021. Finding reviewers for the manuscript took some time because of the unusual combination of subject matter and analytical methods (early childhood development and using unsupervised machine learning). Revisions to the paper were made in mid-2022, based on reviewer feedback. Balancing this with full-time work and study for medical exams was a challenge; I am indebted to my supervisors/co-authors for their help with revisions. The final manuscript, titled Complex early childhood experiences: Characteristics of Northern Territory children across health, education and child protection data1 was accepted for publication at the end of 2022."
  },
  {
    "objectID": "posts/2023-03-01-studying-hds-as-a-junior-doctor/index.html#footnotes",
    "href": "posts/2023-03-01-studying-hds-as-a-junior-doctor/index.html#footnotes",
    "title": "Studying Health Data Science as a junior doctor",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRoper L, He VY, Perez-Concha O, Guthridge S. Complex early childhood experiences: Characteristics of Northern Territory children across health, education and child protection data. PloS one. 2023 Jan 19;18(1):e0280648. https://doi.org/10.1371/journal.pone.0280648↩︎"
  },
  {
    "objectID": "posts/2023-10-09-what If-using-data-storytelling-to-Illustrate-health inequality-in-england/index.html",
    "href": "posts/2023-10-09-what If-using-data-storytelling-to-Illustrate-health inequality-in-england/index.html",
    "title": "What If: Using Data Storytelling to Illustrate Health Inequality in England",
    "section": "",
    "text": "hoyeon.cho@gmail.com\n\n\n au.linkedin.com/in/owen-hoyeon-cho-910b0115\n\n\n\n\n\n\nOwen Cho is a data scientist with a background in corporate strategy. He now leads the data education startup, DeepSkill. After earning his MBA from the University of Cambridge, Owen further specialised as a senior data scientist in Health Policy Analysis, conducting numerous public health data projects, including health utilisation forecasts. He emphasises the importance of balancing hard skills with soft skills for data-driven problem solving in an age flourishing with ever-evolving tools.\n\nBackground\nThe English National Health Service (NHS) has endeavoured to ensure universal healthcare, aiming to provide equal access to all based on clinical needs rather than financial capabilities. However, achieving this ideal has been challenging, with socio-demographic factors often influencing health outcomes and access to care. Recognising the importance of communicating these disparities to a wider audience, a data visualisation competition was initiated.\nIn the competition, my interactive data visualisation titled “What If”, which employed the “scrollytelling” technique, was honoured to receive the Gold Award for Dynamic Visualisation. The insights I gained from studying the universal healthcare system played a pivotal role in shaping my approach and understanding of the issue.\n\n\nApproach\nTo bring the issue of health inequality to life, I crafted a narrative centred around two fictional characters, Ajay and Bob. Both faced similar health challenges, but their socio-economic backgrounds set them on divergent paths. Bob, based in a deprived area, unfortunately, couldn’t survive his condition, while Ajay managed to overcome his.\nUsing a storytelling approach inspired by the film Irreversible, I retraced their journeys in reverse. This method allowed for a poignant exploration of the cascading effects of socio-economic factors on health outcomes. Through a series of thought-provoking “What if” scenarios, the narrative delved deeper into the systemic issues:\n\nSecondary care What if Bob had been able to access timely and appropriate secondary care?\nPrimary care What if Bob had visited his GP more frequently, allowing for earlier detection and prevention of his condition?\nInfrastructure What if Bob had lived in a better-quality, warmer home during his childhood?\nLifestyle What if Bob had maintained a healthier lifestyle and wasn’t obese?\nEducation What if Bob had received a better education, improving his employment opportunities and overall lifestyle?\n\nTo lend a more analytical dimension to the story, I integrated a machine learning model. Drawing from my academic learnings gained from the Health Data Science course, this model quantified the influence of each socio-economic factor on health outcomes using SHAP values.\n\n\n\nA snapshot of images from What if?, which uses dynamic visualisations to reveal a compelling narrative about health inequality. View the full interactive story at healthpolicy.github.io/nhs_whatif\n\n\n\n\nData Source\nVarious data sources from relevant institutions were the pivotal starting point of the project. GOV.UK was instrumental in providing the Index of Multiple Deprivation (IMD) metrics and crucial education statistics, encompassing data on pupil disadvantage and Level 3 attainment by age 19. The Office for National Statistics (ONS) furnished invaluable population estimates and insights on Gross Disposable Household Income. From the NHS, I obtained data shedding light on coronary heart disease mortality and the consequential years of life lost. LG Inform was a valuable resource, offering CHD admission data and insights on prevalent healthy eating habits. Lastly, Public Health England enriched the dataset with information on obesity prevalence, alcohol-related admissions, asthma hospitalizations, and cardiovascular disease mortality rates. All these data points were accessed in February 2020.\n\n\nData Visualisation Technique\nMy approach to data visualisation was a blend of academic knowledge and insights from the Masters course. Taking a cue from Edward Tufte’s emphasis on seamless transitions, I ensured that the visual narrative flowed effortlessly. For instance, the depiction of England’s regions on a map evolved into a chart, illustrating the transformation of geographical divisions into stark health disparities.\nFurthermore, I incorporated the brushing technique in data visualisation. This interactive tool allows users to select specific data subsets and highlight them across various visualisations. It’s an effective way to unearth patterns and trends that might be obscured at first glance, offering viewers a more detailed insight on demand.\nThe significant tool was D3.js, a JavaScript library that enables intricate data visualizations. To seamlessly integrate D3.js visualizations into my project, I utilised the r2d3 package, which facilitated the knitting of D3.js scripts into RMarkdown. This combination ensured that the visualizations were not only interactive but also deeply integrated with the narrative.\nIn wrapping up, this endeavour was more than just an academic exercise; it was a passionate attempt to shed light on the pressing issue of health inequalities. While the recognition was gratifying, the ultimate goal remains: advocating for a more equitable health system for all. In retrospect, this was a great chance to utilise learnings from the Masters program."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Health Data Science Student Hub\n\n\n| Master of Science in Health data Science\n| Clinical Artificial Intelligence\n| Continuous Professional development\n\n\n\n\n\n\n\n\n\n\nThe Master of Science in Health Data Science will prepare you to find the right data, unlock hidden insights and use this information to better support clinical care, inform health policy and improve population health. This degree covers the entire pipeline from comprehension of complex health issues through to data wrangling and management, machine learning, data analytics, data modelling and data communication.\n\n\nAt the Centre for Big Data Research in Health (CBDRH) we aim to enhance the health and wellbeing of all, by maximising the productive use of all possible sources of health big data in medical research.\n\n\nOur master’s degree, graduate diploma and graduate certificate in health data science are pioneering programs that examine data-driven solutions to complex health problems. At UNSW, we’re leading this new approach to healthcare.\nCheck out the videos below to learn more!\n\n\n\n\nApplications of Health Data Science\n\n\n\n\n\nIndustry perspectives of Health Data Science\n\n\n\n\n\nHear our student’s stories"
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software and platforms",
    "section": "",
    "text": "Note\n\n\n\nDifferent convenors have preferences for different platforms, and so the information summarised here may change depending on the course convenor in a given term.\nThe information below was last updated for Term 1 2023.\n\n\n\n\n\n\n\n\n\n\n\n\n\nCourse\n\n\nContent\n\n\nDiscussion\n\n\nProgramming\n\n\n\n\n\n\nHDAT9100 Context for Health Data Science\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9200 Statistical Foundations for Health Data Science\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9300 Computing for Health Data Science\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9400 Data Management & Curation\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9500 Machine Learning I\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9510 Machine Learning II\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9600 Statistical Modelling I\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9700 Statistical Modelling II\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9800 Visualisation & Communication\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9901 Dissertation\n\n\n\n\n\n\n\n\n\n\n\nHDAT9910 Capstone\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9000 Clinical Artificial Intelligence\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCourse\n\n\nSoftware\n\n\n\n\n\n\nHDAT9100 Context for Health Data Science\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\nHDAT9200 Statistical Foundations for Health Data Science\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9300 Computing for Health Data Science\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9400 Data Management & Curation\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9500 Machine Learning I\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9510 Machine Learning II\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9600 Statistical Modelling I\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9700 Statistical Modelling II\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9800 Visualisation & Communication\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9901 Dissertation\n\n\n\n\n\n\nContent\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\nHDAT9910 Capstone\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\nHDAT9900 Clinical Artificial Intelligence\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming"
  },
  {
    "objectID": "software.html#overview-of-software-and-platforms",
    "href": "software.html#overview-of-software-and-platforms",
    "title": "Software and platforms",
    "section": "",
    "text": "Note\n\n\n\nDifferent convenors have preferences for different platforms, and so the information summarised here may change depending on the course convenor in a given term.\nThe information below was last updated for Term 1 2023.\n\n\n\n\n\n\n\n\n\n\n\n\n\nCourse\n\n\nContent\n\n\nDiscussion\n\n\nProgramming\n\n\n\n\n\n\nHDAT9100 Context for Health Data Science\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9200 Statistical Foundations for Health Data Science\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9300 Computing for Health Data Science\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9400 Data Management & Curation\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9500 Machine Learning I\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9510 Machine Learning II\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9600 Statistical Modelling I\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9700 Statistical Modelling II\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9800 Visualisation & Communication\n\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9901 Dissertation\n\n\n\n\n\n\n\n\n\n\n\nHDAT9910 Capstone\n\n\n\n\n\n\n\n\n\n\n\n\nHDAT9000 Clinical Artificial Intelligence\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCourse\n\n\nSoftware\n\n\n\n\n\n\nHDAT9100 Context for Health Data Science\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\nHDAT9200 Statistical Foundations for Health Data Science\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9300 Computing for Health Data Science\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9400 Data Management & Curation\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9500 Machine Learning I\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9510 Machine Learning II\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9600 Statistical Modelling I\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9700 Statistical Modelling II\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9800 Visualisation & Communication\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\nHDAT9901 Dissertation\n\n\n\n\n\n\nContent\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\nHDAT9910 Capstone\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\nHDAT9900 Clinical Artificial Intelligence\n\n\n\n\n\n\nContent\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\n\n\nProgramming"
  },
  {
    "objectID": "people/oscar.html",
    "href": "people/oscar.html",
    "title": "Oscar Perez Concha",
    "section": "",
    "text": "Oscar convenes the machine learning courses HDAT9500 and HDAT9510.  o.perezconcha@unsw.edu.au"
  },
  {
    "objectID": "people/oscar.html#what-publication-are-you-most-proud-of",
    "href": "people/oscar.html#what-publication-are-you-most-proud-of",
    "title": "Oscar Perez Concha",
    "section": "What publication are you most proud of?",
    "text": "What publication are you most proud of?\nIncorporating real-world evidence into the development of patient blood glucose prediction algorithms for the ICU1.\nGlycemic control is an important component of critical care. In this paper, we presented a data-driven method for predicting intensive care unit (ICU) patient response to glycemic control protocols while accounting for patient heterogeneity and variations in care. In particular, we trained and validated a gradient-boosted tree machine learning (ML) algorithm to forecast patient blood glucose and a 95% prediction interval at 2-hour intervals. Our forecasting model using routinely collected EMRs achieved performance comparable to previous models developed in planned research studies using continuous blood glucose monitoring. This paper demonstrates that EMRs can be used to train ML algorithms that may be suitable for incorporation into ICU decision support systems."
  },
  {
    "objectID": "people/oscar.html#whats-the-most-important-take-home-message-from-your-course",
    "href": "people/oscar.html#whats-the-most-important-take-home-message-from-your-course",
    "title": "Oscar Perez Concha",
    "section": "What’s the most important take home message from your course?",
    "text": "What’s the most important take home message from your course?\nTake home message: Learn “how to learn”. That is, rather than just learning a set of machine learning techniques, or how to program in Python, we need to know how to learn what we do not know. For example, it is important to learn how to use the application programming interface (API) documentation and specifications. Or how to interpret what we read from a tutorial or an AI book. This way, the world is our oyster and we are ready to learn new concepts, techniques or programming languages."
  },
  {
    "objectID": "people/oscar.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-to-yourself-as-a-student",
    "href": "people/oscar.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-to-yourself-as-a-student",
    "title": "Oscar Perez Concha",
    "section": "If you could go back in time, what bit of advice would you give to yourself as a student?",
    "text": "If you could go back in time, what bit of advice would you give to yourself as a student?\n\nRead the material before class every week.\nMake the most of the lectures and tutorials.\nTry to understand the concepts/algorithms rather than memorizing without understanding."
  },
  {
    "objectID": "people/oscar.html#who-would-play-you-in-the-biopic-of-your-life",
    "href": "people/oscar.html#who-would-play-you-in-the-biopic-of-your-life",
    "title": "Oscar Perez Concha",
    "section": "Who would play you in the biopic of your life?",
    "text": "Who would play you in the biopic of your life?\n\n\n\n\n\nÓscar Isaac Hernández Estrada."
  },
  {
    "objectID": "people/oscar.html#footnotes",
    "href": "people/oscar.html#footnotes",
    "title": "Oscar Perez Concha",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFitzgerald O, Perez-Concha O, Gallego B, Saxena MK, Rudd L, Metke-Jimenez A, Jorm L. Incorporating real-world evidence into the development of patient blood glucose prediction algorithms for the ICU. Journal of the American Medical Informatics Association. 2021 Aug;28(8):1642-50. https://doi.org/10.1093/jamia/ocab060↩︎"
  },
  {
    "objectID": "people/heidi.html",
    "href": "people/heidi.html",
    "title": "Heidi Welberry",
    "section": "",
    "text": "Heidi convenes the course HDAT9600 Statistical modelling I.  h.welberry@unsw.edu.au"
  },
  {
    "objectID": "people/heidi.html#what-publication-are-you-most-proud-of",
    "href": "people/heidi.html#what-publication-are-you-most-proud-of",
    "title": "Heidi Welberry",
    "section": "What publication are you most proud of?",
    "text": "What publication are you most proud of?\nI am really proud of my paper on psychotropic prescribing among patients with dementia entering residential care1.\nThis paper was the final paper I completed for my PhD and combined several areas of interest including dementia, aged care and primary care. It also addressed a really important topical issue that emerged from the Royal Commission into Aged Care Quality and Safety, namely the overuse of chemical restraints in aged care.\nIt was selected as a highlighted paper in the Medical Journal of Australia with an accompanying invited podcast which was something I had never done before:"
  },
  {
    "objectID": "people/heidi.html#whats-the-most-important-take-home-message-from-your-course",
    "href": "people/heidi.html#whats-the-most-important-take-home-message-from-your-course",
    "title": "Heidi Welberry",
    "section": "What’s the most important take home message from your course?",
    "text": "What’s the most important take home message from your course?\nThere is not always a clear right or wrong with model building, but I think it is always important to make sure you understand very clearly what question it is you are trying to answer and then think hard about if the model you are building is going to answer the question well enough and equally enough for all groups of interest.\nThese are not my words but come from a statistician George Box2:\n\nAll models are approximations. Assumptions, whether implied or clearly stated, are never exactly true. All models are wrong, but some models are useful. So the question you need to ask is not “Is the model true?” (it never is) but “Is the model good enough for this particular application?”"
  },
  {
    "objectID": "people/heidi.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-to-yourself-as-a-student",
    "href": "people/heidi.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-to-yourself-as-a-student",
    "title": "Heidi Welberry",
    "section": "If you could go back in time, what bit of advice would you give to yourself as a student?",
    "text": "If you could go back in time, what bit of advice would you give to yourself as a student?\nI think this depends on which “student me” I am talking to as I have completed three degrees at three completely separate life stages. To the undergraduate me in my early twenties I would definitely say “Be more confident to ask lots of questions and admit when you don’t understand” and “Be more organised and don’t leave everything to the last minute”. To the older me completing postgraduate studies whilst also juggling full-time work or small children I would say “Don’t be too hard on yourself, you are doing the best you can” and the mantra I have had to come to live by: “Don’t let the perfect be the enemy of the good”."
  },
  {
    "objectID": "people/heidi.html#who-would-play-you-in-the-biopic-of-your-life",
    "href": "people/heidi.html#who-would-play-you-in-the-biopic-of-your-life",
    "title": "Heidi Welberry",
    "section": "Who would play you in the biopic of your life?",
    "text": "Who would play you in the biopic of your life?\n\n\n\n\n\nI have always liked Claudia Karvan. I don’t think she looks especially like me but she is a brown-haired Aussie and comes across as down to earth. She has been in some classic Australian TV shows that I grew up with."
  },
  {
    "objectID": "people/heidi.html#footnotes",
    "href": "people/heidi.html#footnotes",
    "title": "Heidi Welberry",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWelberry HJ, Jorm LR, Schaffer AL, Barbieri S, Hsu B, Harris MF, Hall J, Brodaty H. Psychotropic medicine prescribing and polypharmacy for people with dementia entering residential aged care: the influence of changing general practitioners. Medical Journal of Australia. 2021 Aug 2;215(3):130-6. https://doi.org/10.5694/mja2.51153↩︎\np61, Box, Luceño, Paniagua-Quinones (2009) Statistical Control by Monitoring and Adjustment, 2nd Edition, Wiley↩︎"
  },
  {
    "objectID": "people/blanca.html",
    "href": "people/blanca.html",
    "title": "Blanca Gallego Luxan",
    "section": "",
    "text": "Blanca convenes the Clinical AI course HDAT9000.  b.gallego@unsw.edu.au"
  },
  {
    "objectID": "people/blanca.html#what-publication-are-you-most-proud-of",
    "href": "people/blanca.html#what-publication-are-you-most-proud-of",
    "title": "Blanca Gallego Luxan",
    "section": "What publication are you most proud of?",
    "text": "What publication are you most proud of?\nThese are three studies I am proud of:\nDuring my PhD, I developed a model that predicted that the ocean surface currents in the North Atlantic and North Pacific are synchronized on decadal time scales (see Journal of Climate1). Twenty years later, climate scientists from Japan, analysed decades of satellite data to prove that my prediction was correct and that this coupling can help to explain climate events such as the abnormally hot Northern Hemisphere summer of 2018 (see Science2).\nAs a postdoc, while doing research in environmental economics, I formulated a way for allocating responsibility for production impacts consistently amongst all agents throughout demand and supply chains, in a way that reflects their contribution to the production process (see Economic Systems Research3). This formulation is now in used in environmental accounting software (see Green is good for business.\nOn the topic of predictive algorithms in Medicine, I led the first non-disease-specific model that dynamically and simultaneously predicted the future daily probability of remaining days of hospitalization, death, and readmission (see Journal of the American Medical Informatics Association)4. This model allowed for the real-time identification of patient trajectories forecasting expected discharge, expected continuing hospitalization, and expected death. It was featured in the 2016 edition of Stories of Australian Science."
  },
  {
    "objectID": "people/blanca.html#whats-the-most-important-take-home-message-from-your-course",
    "href": "people/blanca.html#whats-the-most-important-take-home-message-from-your-course",
    "title": "Blanca Gallego Luxan",
    "section": "What’s the most important take home message from your course?",
    "text": "What’s the most important take home message from your course?\nMeasures of the predictive performance of an AI algorithm do not incorporate clinical consequences. Further research is required to measure whether a technology can lead to more efficient healthcare systems and better patient outcomes.\nAny clinical AI technology must be feasible (technically, financially, and legally) and desirable (safe, effective, cost-saving and targeting the right problem at the right time)."
  },
  {
    "objectID": "people/blanca.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-to-yourself-as-a-student",
    "href": "people/blanca.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-to-yourself-as-a-student",
    "title": "Blanca Gallego Luxan",
    "section": "If you could go back in time, what bit of advice would you give to yourself as a student?",
    "text": "If you could go back in time, what bit of advice would you give to yourself as a student?\nIf you are doing course work: Focus on understanding the concepts since the technology keeps on changing. If you are doing research: Understand the boundaries of knowledge and practice, aim high, and enjoy the journey."
  },
  {
    "objectID": "people/blanca.html#who-would-play-you-in-the-biopic-of-your-life",
    "href": "people/blanca.html#who-would-play-you-in-the-biopic-of-your-life",
    "title": "Blanca Gallego Luxan",
    "section": "Who would play you in the biopic of your life?",
    "text": "Who would play you in the biopic of your life?\nI am not sure my life would make for a particularly interesting film."
  },
  {
    "objectID": "people/blanca.html#footnotes",
    "href": "people/blanca.html#footnotes",
    "title": "Blanca Gallego Luxan",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nGallego B, Cessi P. Decadal variability of two oceans and an atmosphere. Journal of Climate. 2001 Jul 1;14(13):2815-32. https://doi.org/10.1175/1520-0442(2001)014&lt;2815:DVOTOA&gt;2.0.CO;2↩︎\nKohyama T, Yamagami Y, Miura H, Kido S, Tatebe H, Watanabe M. The Gulf Stream and Kuroshio current are synchronized. Science. 2021 Oct 15;374(6565):341-6. https://www.science.org/doi/10.1126/science.abh3295↩︎\nGallego B, Lenzen M. A consistent input–output formulation of shared producer and consumer responsibility. Economic Systems Research. 2005 Dec 1;17(4):365-91. https://doi.org/10.1080/09535310500283492↩︎\nCai X, Perez-Concha O, Coiera E, Martin-Sanchez F, Day R, Roffe D, Gallego B. Real-time prediction of mortality, readmission, and length of stay using electronic health record data. Journal of the American Medical Informatics Association. 2016 May;23(3):553-61. https://doi.org/10.1093/jamia/ocv110↩︎"
  },
  {
    "objectID": "people/sanja.html",
    "href": "people/sanja.html",
    "title": "Sanja Lujic",
    "section": "",
    "text": "Sanja is a Senior Lecturer and convenor on the courses HDAT9100 Context for Health Data Science and HDAT9400 Data Management & Curation.  s.lujic@unsw.edu.au"
  },
  {
    "objectID": "people/sanja.html#what-publication-are-you-most-proud-of",
    "href": "people/sanja.html#what-publication-are-you-most-proud-of",
    "title": "Sanja Lujic",
    "section": "What publication are you most proud of?",
    "text": "What publication are you most proud of?\nAs a biostatistician, I’ve been involved in a variety of interesting research projects, with a variety of topics (much like our future health data scientists). The paper closest to my heart would be my first PhD paper on the variation of recording of common health conditions in routine hospital data available1. You’ll hear researchers talk about their ‘babies’, and this one was the first one where I had control of the process from start to finish. And I could combine my love of linked data and advanced statistical methods. It was a starting point of my work in chronic disease and multimorbidity, which are my current research interest.\nAn example of a slow burning one would be the one from my Masters’ degree days back in 2008! It was titled Pandemic influenza in Australia: using telephone surveys to measure perceptions of threat and willingness to comply2. I devised a survey, pilot tested it and then analysed the data on perceptions of the threat of pandemic influenza and how people will behave in the event of it occurring. Little did I know that come 2020 all that work will be so very topical! We looked at how likely people were to be vaccinated, isolated and wear a face mask. Deja vu much!"
  },
  {
    "objectID": "people/sanja.html#whats-the-most-important-take-home-message-from-your-course",
    "href": "people/sanja.html#whats-the-most-important-take-home-message-from-your-course",
    "title": "Sanja Lujic",
    "section": "What’s the most important take home message from your course?",
    "text": "What’s the most important take home message from your course?\nAnyone that’s taken my HDAT9400 Management and Curation will know about this one: keep organised! Yes, I do have that as a motto in the class. With piling workload, it’s more imperative than ever to have that skill, and to keep things on track and under control.\nFrom HDAT9100 Context of Health Data Science—keep a list of useful resources and websites. Aggregate data and government reports have a wealth of information which will be useful to you in getting the background information, as well as checking whether your results make sense.\nFor statistical subjects and projects more generally—think about your research question/hypothesis. This is what drives the analysis and interpretation. Always make sure you have your key research questions at the forefront of your mind when you are analysing data. This prevents you from going down too many rabbit holes (and yes, analysts do love analysis!)\nFor programming tasks—think, plan and do. Think of what dataset/analysis you need to answer your question and work backwards from there. Pen and paper will be your best friends as you try and figure out how those outcomes, confounders and variables will need to be derived. Once that’s clear, start coding. And checking. And double checking!"
  },
  {
    "objectID": "people/sanja.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-yourself-as-a-student",
    "href": "people/sanja.html#if-you-could-go-back-in-time-what-bit-of-advice-would-you-give-yourself-as-a-student",
    "title": "Sanja Lujic",
    "section": "If you could go back in time, what bit of advice would you give yourself as a student?",
    "text": "If you could go back in time, what bit of advice would you give yourself as a student?\nStart your assignments early! And there are no silly questions in the class. Lecturers would rather someone ask a question than having silence in the classroom."
  },
  {
    "objectID": "people/sanja.html#who-would-play-you-in-the-biopic-of-your-life",
    "href": "people/sanja.html#who-would-play-you-in-the-biopic-of-your-life",
    "title": "Sanja Lujic",
    "section": "Who would play you in the biopic of your life?",
    "text": "Who would play you in the biopic of your life?\n\n\n\n\n\nTina Fay\n\n\n\n\nOh I’d love to say Monica Bellucci, purely because of her Italian charm. Looks wise, I have highest match with Tina Fay (according to the StarByFace app)!"
  },
  {
    "objectID": "people/sanja.html#footnotes",
    "href": "people/sanja.html#footnotes",
    "title": "Sanja Lujic",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLujic S, Watson DE, Randall DA, Simpson JM, Jorm LR. Variation in the recording of common health conditions in routine hospital data: study using linked survey and administrative data in New South Wales, Australia. BMJ open. 2014 Sep 1;4(9):e005768. http://dx.doi.org/10.1136/bmjopen-2014-005768↩︎\nBarr M, Raphael B, Taylor M, Stevens G, Jorm L, Giffin M, Lujic S. Pandemic influenza in Australia: using telephone surveys to measure perceptions of threat and willingness to comply. BMC infectious diseases. 2008 Dec;8(1):1-4. https://doi.org/10.1186/1471-2334-8-117↩︎"
  },
  {
    "objectID": "tutorials/tutorial_presentation.html#in-this-talk",
    "href": "tutorials/tutorial_presentation.html#in-this-talk",
    "title": "Factors which influence birthweight",
    "section": "In this talk",
    "text": "In this talk\nIn this presentation we will briefly present our analysis of the effect of smoking on birthweight using a publicly-available data set. There are six sections:\n\n\nThe research question\nCurating the data\nExploring the data\nDescriptive Modelling\nPredictive modelling\nConclusions"
  },
  {
    "objectID": "tutorials/tutorial_presentation.html#the-research-question",
    "href": "tutorials/tutorial_presentation.html#the-research-question",
    "title": "Factors which influence birthweight",
    "section": "The research question",
    "text": "The research question\nIn this analysis, we addressed two research questions:\n\nWhat is the relationship between smoking during pregnancy and a child’s birthweight?\nCan maternal factors measured during pregnancy be used to accurately predict infants at risk of low birthweight?"
  },
  {
    "objectID": "tutorials/lesson4.html",
    "href": "tutorials/lesson4.html",
    "title": "Step 4. Descriptive Modelling",
    "section": "",
    "text": "Overview\nStatistical modelling is the cornerstone of evidence-based decision-making in healthcare. By crunching numbers and analysing patterns, we gain insights into disease trends, treatment effectiveness, and the factors influencing health outcomes. It’s like having a powerful magnifying glass that allows us to zoom in on the crucial details within a vast dataset.\nOur exploratory data analysis has already gone some way to answering our first question What is the relationship between smoking during pregnancy and a child’s birthweight? It looks like children born to mums who smoked during pregnancy have, on average, a lower birthweight compared to children born to non-smokers.\n\n\n\n\n\n\n\nIt looks like children born to mums who smoked during pregnancy have a lower birthweight, on average, compared to children born to non-smokers.\nBut can we be sure this is the right interpretation? Is the difference meaningful or could it just be noise in the data or random chance?\nTo answer these questions we can use linear regression—the workhorse of statistical modeling. At its core, linear regression helps us explore the linear relationship between a dependent variable and one or more independent variables. Suppose we’re examining the impact of factors like maternal age, smoking, and hypertension on birthweight. Linear regression enables us to quantify these relationships, providing us with coefficients that represent the strength and direction of each influence. It’s like having a mathematical roadmap to understand how changes in one variable correlate with changes in another.\n\n\n\nCreated using Stable Diffusion — human + AI.\n\n\nBelow is the code to fit a linear model in R using the lm() function. Note that we specify the outcome variable birthweight (or bwt), the explanatory variable smoke, and the dataset birthwt.\n\nmodel1 &lt;- lm(bwt ~ smoke, data = birthwt)\n\nAnd here are the model results, presented as a table.\n\n\n\n\n\n \nBirthweight\n\n\nPredictors\nEstimates\nCI\np\n\n\nBaseline\n3056\n2924 – 3188\n&lt;0.001\n\n\nSmokers\n-284\n-495 – -73\n0.009\n\n\nObservations\n189\n\n\n\n\n\n\n\nWe can interpret this as follows:\n\nThe baseline coefficient is 3,056. In this case, the baseline refers to children born to non-smokers, and the estimate tells us that these children weighted 3,056 grams on average.\nThe 95% confidence interval (CI) for this estimate ranges from 2,924 grams to 3,188 grams. This provides a sense of how certain we are about the estimate of 3,056 grams. If we were to repeat the study or experiment many times and calculate the CI each time, we would expect the true value of the coefficient to fall within the range of 2,924–3,188 for about 95% of those repetitions.\nThe coefficient for smokers is -284. This tells us that, on average, babies born to smoking mums were 284 grams lighter than babies born to non-smokers.\nThe 95% confidence interval (CI) for this estimate ranges from -495 grams to -73 grams.\n\n\n\n\n\n\n\n\n\nStudying Health Data Science at UNSW Sydney\n\n\n\nLearn the fundamentals of statistical modelling it the course HDAT9600 Statistical Modelling I\nPush your skills further to model complex health data structures in HDAT9700 Statistical Modelling II.\n\n\n\nThese results confirm that there is a statistically significant association between maternal smoking and birthweight. Children of mothers who smoked during pregnancy are born with a lower birthweight compared to children of mothers who did not smoke, on average. The estimated difference is 284 grams lighter on average but—based on the observed data—it could be as much as 495 grams lighter on average or as little as 73 grams lighter on average (or even more, or less, but that would be very, very unlikely).\nImportantly, this result by itself does not necessarily mean that the observed differences are caused directly by smoking. It could be that mothers who smoked have very different characteristics compared to mothers who did not smoke. For example, perhaps smoking mums disproportionately came from disadvantaged backgrounds with higher barriers to receive antenatal care and it is that difference that explains the differences in birthweight rather than smoking alone. Advanced analytical methods can help us to distinguish causation from mere correlation.\n\n\nIncorporating knowledge of underlying biological and social processes into statistical analyses is an essential step in teasing apart causation from mere correlation. Often this knowledge is summarised in the form a Directed Acyclic Graph (DAG). Some of the MSc HDS course instructors have developed an R software package and web application to help improve your understanding of these concepts.\n\n\n\n\n\n Test your understanding\n\nTest your understanding by answering these questions based on the model output above\n\n\n\nFill in the blank Children of mothers who smoked during pregnancy were on average grams lighter compared to children of mothers who did not smoke during pregnancy.\nTrue or False The 95% confidence interval for the coefficient for maternal smoking includes 0 TRUEFALSE\nChoose the correct answer There is a positivenegative association between maternal smoking and birthweight.\n\n\n\n\nNext steps\n\n\n Back to the main menu \n\n\n Step 5. Predictive modelling"
  },
  {
    "objectID": "tutorials/lesson3.html",
    "href": "tutorials/lesson3.html",
    "title": "Step 3. Exploring the data",
    "section": "",
    "text": "Overview\nGreat, now that we have a better understanding of the available dataset, we can start to do some exploratory data analysis.\nThe purpose of this exploratory phase is to gain insights into the structure, distribution, and characteristics of the data before applying more complex statistical or machine learning techniques. Understanding the data will help to inform our analytic approach to answer our key research questions. As a reminder, they are:\n\nWhat is the relationship between smoking during pregnancy and a child’s birthweight?\nCan maternal factors measured during pregnancy be used to accurately predict infants at risk of low birthweight?\n\nIn this section we will use statistical summaries and data visualisation to get a feel for our birthweight dataset.\n\n\n\nCreated using Stable Diffusion — human + AI.\n\n\n\n\nStatistical summaries\nLet’s start by printing a table of the univariate distribution of each variable.\n\nFor dichotomous variables like Low Birthweight, we can see that 59 children (or 39%) were born with low birthweight\nFor continuous variables like Age we can see that the average maternal age was 23 years and the interquartile range was 19 to 26 years (i.e. 25% of mothers were 19 years or younger and 25% were 26 years and older)\nFor categorical variables like Race we can see that 96 mothers (or 51% of the total) were White, 26 mothers were Black (14%) and 67 mothers were categorised as “Other” (35%).\n\n\n\nCode\nlibrary(gtsummary) # load library for making nice tables\n\n# Print the table\ntbl_summary(birthwt_clean, label = varLabels)\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 1891\n    \n  \n  \n    Low birthweight\n59 (31%)\n    Age\n23 (19, 26)\n    Weight at last menstrual period (lbs)\n121 (110, 140)\n    Race\n\n        White\n96 (51%)\n        Black\n26 (14%)\n        Other\n67 (35%)\n    Smoking during pregnancy\n\n        Non-smoker\n115 (61%)\n        Smoker\n74 (39%)\n    Previous premature labours\n\n        0\n159 (84%)\n        1\n24 (13%)\n        2\n5 (2.6%)\n        3\n1 (0.5%)\n    History of hypertension\n12 (6.3%)\n    Uterine irritability\n28 (15%)\n    Physician visits during first trimester\n\n        0\n100 (53%)\n        1\n47 (25%)\n        2\n30 (16%)\n        3\n7 (3.7%)\n        4\n4 (2.1%)\n        6\n1 (0.5%)\n    Birthweight (g)\n2,977 (2,414, 3,487)\n  \n  \n  \n    \n      1 n (%); Median (IQR)\n    \n  \n\n\n\n\nBecause we are interested in comparing children by their birthweight, we can look at a second table that compares children who were and were not born with low birthweight.\n\n\nCode\nbirthwt_clean |&gt; \n  tbl_summary(\n    by=low, \n    label=varLabels) |&gt; \n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Low birthweight**\")\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      \n        Low birthweight\n      \n    \n    \n      No, N = 1301\n      Yes, N = 591\n    \n  \n  \n    Age\n23 (19, 28)\n22 (20, 25)\n    Weight at last menstrual period (lbs)\n124 (113, 147)\n120 (104, 130)\n    Race\n\n\n        White\n73 (56%)\n23 (39%)\n        Black\n15 (12%)\n11 (19%)\n        Other\n42 (32%)\n25 (42%)\n    Smoking during pregnancy\n\n\n        Non-smoker\n86 (66%)\n29 (49%)\n        Smoker\n44 (34%)\n30 (51%)\n    Previous premature labours\n\n\n        0\n118 (91%)\n41 (69%)\n        1\n8 (6.2%)\n16 (27%)\n        2\n3 (2.3%)\n2 (3.4%)\n        3\n1 (0.8%)\n0 (0%)\n    History of hypertension\n5 (3.8%)\n7 (12%)\n    Uterine irritability\n14 (11%)\n14 (24%)\n    Physician visits during first trimester\n\n\n        0\n64 (49%)\n36 (61%)\n        1\n36 (28%)\n11 (19%)\n        2\n23 (18%)\n7 (12%)\n        3\n3 (2.3%)\n4 (6.8%)\n        4\n3 (2.3%)\n1 (1.7%)\n        6\n1 (0.8%)\n0 (0%)\n    Birthweight (g)\n3,267 (2,948, 3,651)\n2,211 (1,928, 2,396)\n  \n  \n  \n    \n      1 Median (IQR); n (%)\n    \n  \n\n\n\n\nSome distinct differences for low birthweight children are starting to emerge. For example:\n\nMothers of low birthweight children were more likely to be smokers (51%) compared to non-smokers (34%).\nMothers of low birthweight children were more likely to have a history of hypertension (12% among low birthweight children compared to 3.8% among non-low birthweight children)\n\n\n\n\n\n\n\n\n\nStudying Health Data Science at UNSW Sydney\n\n\n\nBeing able to summarise statistical information is a foundation skill for a health data scientist. The course HDAT9200 Statistical Foundations for Health Data Science provides a solid understanding of the principles of statistics using the R programming language.\nYou will learn to write clear, efficient and correct computer code in the course HDAT9300 Computing for Health Data Science, which uses the Python programming language.\n\n\n\n\n\n\nData visualisation\nAbove we confirmed that babies born to mums who smoked during pregnancy had lower average birthweight compared to those that did not smoke. Let’s use data visualisation to compare the full distribution of birthweights by maternal smoking status. Remember, you can click the  Code icon to reveal the underlying R code that creates this chart.\n\n\nCode\nlibrary(ggplot2) # Load ggplot2 library for visualising data\n\nbirthwt_clean |&gt; \n    ggplot(aes(x = smoke, y = bwt, fill=smoke)) +\n      geom_boxplot() +\n        scale_x_discrete(\"\") +\n        scale_y_continuous(\"Birthweight (grams)\", labels = scales::comma) +\n        scale_fill_manual(\"Smoking status\", values = c('#03d77f', '#fb706a')) +\n        labs(title=\"Birthweight by maternal smoking status\") +\n        theme_minimal() +\n        theme(legend.position = 'none')\n\n\n\n\n\nThis type of chart is called a grouped boxplot. These plots are good for quickly comparing the distribution of a numerical variable across two of more categorical variables. In this case, we can compare the distribution of birthweight for babies of smoking mums and non-smoking mums.\nThe dark horizontal line at the centre of the box indicates the median birthweight for each group. The upper and lower borders of the boxes indicate the 25th and 75th quartiles and the vertical spikes emerging at either end indicate the full range of the data.\nWe can see that babies born to non-smoking mums are heavier on average compared to babies born to smoking mums, although there is a lot of overlap in the distributions.\n\n\n\n\n\n\n\n\nStudying Health Data Science at UNSW Sydney\n\n\n\nLearn how to tell compelling visual stories with data in HDAT9800 Visualisation & Communication.\n\n\n\n\nBelow is a visualisation of the same data using a density plot. If you compare the code for this plot to the previous one, you will see that very little has changed. This is the power of the ggplot package: one consistent framework can produce many different types of graphs!\n\n\nCode\nlibrary(ggplot2) # Tools for visualising data\n\nbirthwt_clean |&gt; \n    ggplot(\n      aes(x = bwt, fill = smoke, color = smoke)) +\n        geom_density(alpha=0.8) +\n          scale_x_continuous(\"Birthweight\") +\n          scale_y_continuous(\"Density\") +\n          scale_color_manual(\"Smoking status\", values = c('#03d77f', '#fb706a')) +\n          scale_fill_manual(\"Smoking status\", values = lighten(c('#03d77f', '#fb706a'), 0.4)) +\n          labs(title=\"Birthweight by maternal smoking status\") +\n          theme_minimal() +\n          theme(legend.position = 'top')\n\n\n\n\n\nBoth plots above illustrate the same message, babies born to mums who smoked during pregnancy have a lower birthweight on average, compared to babies of non-smokers, although there is a lot of overlap for both groups.\n\n\n\n Test your understanding\nTest your understanding by answering these questions based on the tables and figures above.\n\nFill in the blank Among the 59 children born with low birthweight, % had mothers who smoked during pregnancy.\nTrue or False Children born to mothers who smoked during pregnancy always have lower birthweight than children born to mothers who did not smoke? TRUEFALSE\n\n\n\n\nNext steps\n\n\n Back to the main menu \n\n\n Step 4. Descriptive modelling"
  },
  {
    "objectID": "tutorials/lesson1.html",
    "href": "tutorials/lesson1.html",
    "title": "Step 1. The research question",
    "section": "",
    "text": "A health data scientist is someone who answers questions about health using data and analytics. This encompasses questions about patient well-being, diseases, treatments, medications, health systems, and many other areas of clinical and medical interest.\nThe first step in any health data analysis is understanding the research question. Once the question is clear, the relevant data and necessary analytic approaches will fall in to place much more quickly.\nIn this guided tutorial, you will be addressing two research questions:\n\nWhat is the relationship between smoking during pregnancy and a child’s birthweight?\nCan maternal factors measured during pregnancy be used to accurately predict infants at risk of low birthweight?\n\nBelow you can read about why understanding and predicting low birthweight is an important research goal, the types of factors that might influence birth, and how birthweight is recorded and reported in Australia.\n\n\n\nCreated using Stable Diffusion — human + AI."
  },
  {
    "objectID": "tutorials/lesson1.html#footnotes",
    "href": "tutorials/lesson1.html#footnotes",
    "title": "Step 1. The research question",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nGhimire, P.R.; Mooney, J.; Fox, L.; Dubois, L. Smoking Cessation during the Second Half of Pregnancy Prevents Low Birth Weight among Australian Born Babies in Regional New South Wales. Int. J. Environ. Res. Public Health 2021, 18, 3417. https://doi.org/10.3390/ijerph18073417↩︎"
  }
]